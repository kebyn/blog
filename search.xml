<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[MySQL无密码登陆（MySQL_config_editor用法）]]></title>
      <url>%2F2017%2F03%2F16%2Fmysql-nopassword%2F</url>
      <content type="text"><![CDATA[mysql_config_editor是MySQL5.6.6以后版本的工具。这个工具可以认证信息加密存储在.mylogin.cnf中，通常这个文件在Linux用户的家目录和Windows的%APPDATA%\MySQL目录中。.mylogin.cnf文件未加密的示例如下：12345678[client]user = mydefaultnamepassword = mydefaultpasshost = 127.0.0.1[mypath]user = myothernamepassword = myotherpasshost = localhost 实际使用时密码会被加密。 mysql_config_editor的用法shell&gt; mysql_config_editor [program_options] command [command_options] 添加认证信息12345678910111213141516171819202122#添加认证时查看帮助信息shell&gt; mysql_config_editor --help setshell&gt; mysql_config_editor set --help#添加认证信息shell&gt; mysql_config_editor set --login-path=client --host=localhost --user=localuser --passwordEnter password: enter password &quot;localpass&quot; hereshell&gt; mysql_config_editor set --login-path=remote --host=remote.example.com --user=remoteuser --passwordEnter password: enter password &quot;remotepass&quot; here#查看已经添加的认证信息shell&gt; mysql_config_editor print --all[client]user = localuserpassword = *****host = localhost[remote]user = remoteuserpassword = *****host = remote.example.com 无密码登陆1234567shell&gt; mysql --login-path=remoteshell&gt; mysql --login-path=client#因为mysql默认读取login-path=client的认证信息，所以上条命令可以简化如下shell&gt; mysqlshell&gt; mysql --login-path=remote --host=remote2.example.com 移除认证信息12shell&gt; mysql_config_editor remove --login-path=mypath --usershell&gt; mysql_config_editor remove --login-path=mypath 查看帮助shell&gt; mysql_config_editor command --help 参考链接https://dev.mysql.com/doc/refman/5.6/en/mysql-config-editor.htmlhttps://dev.mysql.com/doc/refman/5.7/en/mysql-config-editor.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[架构]]></title>
      <url>%2F2017%2F02%2F15%2F%E6%9E%B6%E6%9E%84%2F</url>
      <content type="text"><![CDATA[DNS服务器 如果资金充足的话，建议使用BGP机房，2-3台DNS服务器均衡，通常使用bind软件。 BGP（边界网关协议）主要用于互联网AS（自治系统）之间的互联，BGP的最主要功能在于控制路由的传播和选择最好的路由。 中国网通 、中国电信、中国铁通和一些大的民营IDC运营商都具有AS号，全国各大网络运营商多数都是通过BGP协议与自身的AS号来实现多线互联的。 使用此方案来实现多线路互联，IDC需要在CNNIC（中国互联网信息中心）或APNIC（亚太网络信息中心）申请自己的IP地址段和AS号，然后通过BGP协议将此段IP地址广播到其它的网络运营商的网络中。 使用BGP协议互联后，网络运营商的所有骨干路由设备将会判断到IDC机房IP段的最佳路由，以保证不同网络运营商用户的高速访问。 BGP 机房的优点： 服务器只需要设置一个IP地址，最佳访问路由是由网络上的骨干路由器根据路由跳数与其它技术指标来确定的，不会占用服务器的任何系统资源。 服务器的上行路由与下行路由都能选择最优的路径，所以能真正实现高速的单IP高速访问。 由于BGP协议本身具有冗余备份、消除环路的特点，所以当IDC服务商有多条BGP互联线路时可以实现路由的相互备份，在一条线路出现故障时路由会自动切换到其它线路。 使用BGP协议还可以使网络具有很强的扩展性可以将IDC网络与其他运营商互联，轻松实现单IP多线路，做到所有互联运营商的用户访问都很快。这个是双IP双线无法比拟的。 如果资金紧的话，可以购买专业的dns服务，比如国内的dnspod。 CDN服务器 一开始如果想省事，可以买专业公司的服务，但随着发展成本会越来越高。 思必达(chinaspeeds)、蓝汛(chinacache) 自建的话，可能分别搭建，放电信、联通、移动等不同机房的服务器，通过dns做动态解析。 超大网站的话，可以用Squid 普通中至大型用nginx 内部玩玩用varnish。 前端均衡 资金充足的话，可以使用硬件设备，几十万一台。 F5 Radware、Array、A10、Cisco、深信服和华夏创新等 自已有技术队伍的 就用nginx/haproxy+keepalived等自已组建前端。 均衡的方式都比较灵活，随机、权重、ip、url都有。 同步的问题 普通的可以实时文件同步。 数据库同步。 逻辑备份： 备份的是建表、建库、插入等操作所执行SQL语句，适用于中小型数据库，效率相对较低。 mysqldump mydumper 物理备份： 直接复制数据库文件，适用于大型数据库环境，不受存储引擎的限制，但不能恢复到异构系统中如Windows。 xtrabackup inbackup lvm snapshot 后端的应用服务器和数据库集群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[BASH_CVE-2014-6271]]></title>
      <url>%2F2017%2F01%2F10%2Fbash_CVE-2014-6271%2F</url>
      <content type="text"><![CDATA[很多人或许对上半年发生的安全问题“心脏流血”（Heartbleed Bug）事件记忆颇深，这两天，又出现了另外一个“毁灭级”的漏洞——Bash软件安全漏洞。这个漏洞由法国GNU/Linux爱好者Stéphane Chazelas所发现。随后，美国电脑紧急应变中心（US-CERT）、红帽以及多家从事安全的公司于周三（北京时间9月24日）发出警告。 关于这个安全漏洞的细节可参看美国政府计算安全的这两个漏洞披露：CVE-2014-6271 和 CVE-2014-7169。 这个漏洞其实是非常经典的“注入式攻击”，也就是可以向 bash注入一段命令，从bash1.14 到4.3都存在这样的漏洞。我们先来看一下这个安全问题的症状。 Shellshock (CVE-2014-6271)下面是一个简单的测试： $ env VAR=&apos;() { :;}; echo Bash is vulnerable!&apos; bash -c &quot;echo Bash Test&quot; 如果你发现上面这个命令在你的bash下有这样的输出，那你就说明你的bash是有漏洞的： Bash is vulnerable! Bash Test 简单地看一下，其实就是向环境变量中注入了一段代码 echo Bash is vulnerable。关于其中的原理我会在后面给出。 很快，CVE-2014-6271的官方补丁出来的了——Bash-4.3 Official Patch 25。 AfterShock – CVE-2014-7169 （又叫Incomplete fix to Shellshock）但随后，马上有人在Twitter上发贴——说这是一个不完整的fix，并给出了相关的攻击方法。 也就是下面这段测试代码（注意，其中的sh在linux下等价于bash）： env X=&apos;() { (a)=&gt;\&apos; sh -c &quot;echo date&quot;; cat echo 上面这段代码运行起来会报错，但是它要的就是报错，报错后会在你在当前目录下生成一个echo的文件，这个文件的内容是一个时间文本。下面是上面 这段命令执行出来的样子。 $ env X=&apos;() { (a)=&gt;\&apos; sh -c &quot;echo date&quot;; cat echo sh: X: line 1: syntax error near unexpected token `=&apos; sh: X: line 1: `&apos; sh: error importing function definition for `X&apos; Sat Sep 27 22:06:29 CST 2014 这段测试脚本代码相当的诡异，就像“天书”一样，我会在后面详细说明这段代码的原理。 原理和技术细节要说清楚这个原理和细节，我们需要从 bash的环境变量开始说起。 bash的环境变量环境变量大家知道吧，这个不用我普及了吧。环境变量是操作系统运行shell中的变量，很多程序会通过环境变量改变自己的执行行为。在bash中要定义一个环境变量的语法很简单（注：=号的前后不能有空格）： $ var=&quot;hello world&quot; 然后你就可以使用这个变量了，比如：echo $var什么的。但是，我们要知道，这个变量只是一个当前shell的“局部变量”，只在当前的shell进程中可以访问，这个shell进程fork出来的进程是访问不到的。 你可以做这样的测试： $ var=&quot;hello coolshell&quot; $ echo $var hello coolshell $ bash $ echo $var 上面的测试中，第三个命令执行了一个bash，也就是开了一个bash的子进程，你就会发现var不能访问了。 为了要让shell的子进程可以访问，我们需要export一下： $ export var=&quot;hello coolshell&quot; 这样，这个环境变量就会在其子进程中可见了。 如果你要查看一下有哪些环境变量可以在子进程中可见（也就是是否被export了），你可使用env命令。不过，env命令也可以用来定义export的环境变量。如下所示： $ env var=&quot;hello haoel&quot; 有了这些基础知识还不够，我们还要知道一个基础知识——shell的函数。 bash的函数在bash下定义一个函数很简单，如下所示： $ foo(){ echo &quot;hello coolshell&quot;; } $ foo hello coolshell 有了上面的环境变量的基础知识后，你一定会想试试这个函数是否可以在子进程中调用，答案当然是不行的。 $ foo(){ echo &quot;hello coolshell&quot;; } $ foo hello coolshell $ bash $ foo bash: foo: command not found 你看，和环境变量是一样的，如果要在子进程中可以访问的话，那么，还是一样的，需要export，export有个参数 -f，意思是export一个函数。如： $ foo(){ echo &quot;hello coolshell&quot;; } $ foo hello coolshell $ export -f foo $ bash $ foo hello coolshell 好了，我讲了这么半天的基础知识，别烦，懂了这些，你才会很容易地理解这两个漏洞是怎么回事。 好，现在要进入正题。 bash的bug从上面我们可以看到，bash的变量和函数用了一模一样的机制，如果你用env命令看一下export出来的东西，你会看到上面我们定义的变量和函数都在，如下所示（我省略了其它的环境变量）： $ env var=hello coolshell foo=() { echo &quot;hello coolshell&quot; } 原来，都用同样的方式啊——无论是函数还是变量都是变量啊。于是，看都不用看bash的源代码，聪明的黑客就能猜得到——bash判断一个环境变量是不是一个函数，就看它的值是否以”()”开始。于是，一股邪念涌上心头。 黑客定义了这样的环境变量（注：() 和 { 间的空格不能少）： $ export X=&apos;() { echo &quot;inside X&quot;; }; echo &quot;outside X&quot;;&apos; env一下，你会看到X已经在了： $ env X=(){ echo &quot;inside X&quot;; }; echo &quot;outside X&quot;; 然后，当我们在当前的bash shell进程下产生一个bash的子进程时，新的子进程会读取父进程的所有export的环境变量，并复制到自己的进程空间中，很明显，上面的X变量的函数的后面还注入了一条命令：echo “outside X”，这会在父进程向子进程复制的过程中被执行吗？（关于fork相关的东西你可以看一下我以前写的《fork的一个面试题》） 答案是肯定的。 $ export X=&apos;() { echo &quot;inside X&quot;; }; echo &quot;outside X&quot;;&apos; $ bash outside X 你看，一个代码注入就这样完成了。这就是bash的bug—— 函数体外面的代码被默认地执行了。 我们并不一定非要像上面那样创建另一个bash的子进程，我们可以使用bash -c的参数来执行一个bash子进程命令。就像这个安全漏洞的测试脚本一样： env VAR=&apos;() { :;}; echo Bash is vulnerable!&apos; bash -c &quot;echo Bash Test&quot; 其中，() { :;} 中的冒号就相当于/bin/true，返回true并退出。而bash -c其实就是在spawn一个bash的echo的子进程，用于触发函数体外的echo命令。所以，更为友好一点的测试脚本应该是： env VAR=&apos;() { :;}; echo Bash is vulnerable!&apos; bash -c &quot;echo 如果你看到了vulnerable字样说明你的bash有安全问题”OK，你应该明白这个漏洞是怎么一回事了吧。 bash漏洞的影响有多大在网上看到好多人说这个漏洞不大，还说这个事只有那些陈旧的执行CGI脚本的网站才会有，现在已经没有网站用CGI了。我靠，这真是无知者无畏啊。 我举个例子，如果你的网站中有调用操作系统的shell命令，比如你用PHP执行个exec之类的东西。这样的需求是有的，特别是对于一些需要和操作系统交互的重要的后台用于系统管理的程序。于是就会开一个bash的进程来执行。 我们还知道，现在的HTTP服务器基本上都是以子进程式的，所以，其中必然会存在export 一些环境变量的事，而有的环境变量的值是从用户端来的，比如：HTTP_USER_AGENT这样的环境变量，只由浏览器发出的。其实这个变量你想写成什么就写成什么。 于是，我可以把这个HTTP_USER_AGENT的环境变量设置成上述的测试脚本，只不过，我会把echo Bash is vulnerable!这个东西换成别的更为凶残的命令。呵呵。 关于这个漏洞会影响哪些已有的系统，你可以自己Google，几乎所有的报告这个漏洞的文章都说了（比如：这篇，这篇），我这里就不复述了。 注：如果你要看看你的网站有没有这样的问题，你可以用这个在线工具测试一下：‘ShellShock’ Bash Vulnerability CVE-2014-6271 Test Tool。 现在，你知道这事可能会很大了吧。还不赶快去打补丁。（注，yum update bash 把bash版本升级到 4.1.2-15.el6_5.2 ， ） 关于 AfterShock – CVE-2014-7169 测试脚本的解释很多同学没有看懂下面这个测试脚本是什么意思，我这里解释一下。 env X=&apos;() { (a)=&gt;\&apos; sh -c &quot;echo date&quot;; cat echo X=’() { (a)=&gt;\’ 这个不用说了，定义一个X的环境变量。但是，这个函数不完整啊，是的，这是故意的。另外你一定要注意，\’不是为了单引号的转义，X这个变量的值就是 () { (a)=&gt;\其中的 (a)=这个东西目的就是为了让bash的解释器出错（语法错误）。语法出错后，在缓冲区中就会只剩下了 “&gt;\”这两个字符。于是，这个神奇的bash会把后面的命令echo date换个行放到这个缓冲区中，然后执行。相当于在shell 下执行了下面这个命令： $ &gt;\ echo date 如果你了解bash，你会知道 \ 是用于命令行上换行的，于是相当于执行了： $ &gt;echo date 这不就是一个重定向么？上述的命令相当于： $ date &gt; echo 于是，你的当前目录下会出现一个echo的文件，这个文件的内容就是date命令的输出。 能发现这个种玩法的人真是个变态，完全是为bash的源代码量身定制的一个攻击。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CDN中记录真实IP]]></title>
      <url>%2F2016%2F12%2F25%2Fcdn_ip%2F</url>
      <content type="text"><![CDATA[使用CDN后在网页服务器日志中显示真实的用户IP地址真实IP：为解决这个问题，可以通过在云加速转发的HTTP头信息中增加 X-Forwarded-For 信息，用于记录客户端的真实IP，这时web服务器的日志就可以使用 $http_x_forwarded_for变量记录远程客户端的真实IP。格式如下： Nginx&#39;$http_x_forwarded_for - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &#39;; ApacheLogFormat &quot;%{X-Forwarded-For}i %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%{Referer}i\&quot; \&quot;%{User-Agent}i\&quot;&quot; ASPRequest.ServerVariables(&quot;HTTP_X_FORWARDED_FOR&quot;) PHP$_SERVER[&quot;HTTP_X_FORWARDED_FOR&quot;] JSPrequest.getHeader(&quot;HTTP_X_FORWARDED_FOR&quot;)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python中不能打开ssl链接]]></title>
      <url>%2F2016%2F12%2F17%2Fpython_ssl%2F</url>
      <content type="text"><![CDATA[SSL: CERTIFICATE_VERIFY_FAILEDpython中不能打开ssl链接12- import requests.packages.urllib3.util.ssl_ requests.packages.urllib3.util.ssl_.DEFAULT_CIPHERS = ‘ALL&apos;- pip install requests python-ssl_error 使用ssl创建未经验证的上下文，在urlopen中传入上下文参数 123456import sslimport urllib2# This restores the same behavior as before.context = ssl._create_unverified_context()print urllib2.urlopen(&quot;https://www.baidu.com&quot;, context=context).read() 导入ssl时关闭全局证书验证 123456789import sslimport urllib2# Legacy Python that doesn&apos;t verify HTTPS certificates by default ssl._create_default_https_context = ssl._create_unverified_context# Handle target environment that doesn&apos;t support HTTPS verification#ssl._create_default_https_context = _create_unverified_https_contextprint urllib2.urlopen(&quot;https://www.baidu.com&quot;).read() 官方文档介绍]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[minecraft]]></title>
      <url>%2F2016%2F11%2F11%2Fminecraft%2F</url>
      <content type="text"><![CDATA[MineCraft官网购买链接store 客户端下载client 服务器版本下载地址server 2016/10/04日解析地址：minecraft_server.1.10.2.jar 2017/03/10日解析地址：minecraft_server.1.11.2.jar 启动/startup1java -Xmx1024M -Xms512M -jar minecraft_server.1.11.2.jar nogui 服务器设置/Setting up a serverone two 自启文件/Server startup script1wget -O minecraft &quot;http://minecraft.gamepedia.com/Tutorials/Server_startup_script/Script?action=raw&quot; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201#!/bin/bash# /etc/init.d/minecraft# version 0.4.2 2016-02-09 (YYYY-MM-DD)#### BEGIN INIT INFO# Provides: minecraft# Required-Start: $local_fs $remote_fs screen-cleanup# Required-Stop: $local_fs $remote_fs# Should-Start: $network# Should-Stop: $network# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Minecraft server# Description: Starts the minecraft server### END INIT INFO#SettingsSERVICE=&apos;minecraft_server.jar&apos;SCREENNAME=&apos;minecraft_server&apos;OPTIONS=&apos;nogui&apos;USERNAME=&apos;minecraft&apos;WORLD=&apos;world&apos;MCPATH=&apos;/home/minecraft&apos;BACKUPPATH=&apos;/media/remote.share/minecraft.backup&apos;MAXHEAP=2048MINHEAP=1024HISTORY=1024CPU_COUNT=1INVOCATION=&quot;java -Xmx$&#123;MAXHEAP&#125;M -Xms$&#123;MINHEAP&#125;M -XX:+UseConcMarkSweepGC \-XX:+CMSIncrementalPacing -XX:ParallelGCThreads=$CPU_COUNT -XX:+AggressiveOpts \-jar $SERVICE $OPTIONS&quot; ME=`whoami`as_user() &#123; if [ &quot;$ME&quot; = &quot;$USERNAME&quot; ] ; then bash -c &quot;$1&quot; else su - &quot;$USERNAME&quot; -c &quot;$1&quot; fi&#125;mc_start() &#123; if pgrep -u $USERNAME -f $SERVICE &gt; /dev/null ; then echo &quot;$SERVICE is already running!&quot; else echo &quot;Starting $SERVICE...&quot; cd $MCPATH as_user &quot;cd $MCPATH &amp;&amp; screen -h $HISTORY -dmS $&#123;SCREENNAME&#125; $INVOCATION&quot; sleep 7 if pgrep -u $USERNAME -f $SERVICE &gt; /dev/null ; then echo &quot;$SERVICE is now running.&quot; else echo &quot;Error! Could not start $SERVICE!&quot; fi fi&#125;mc_saveoff() &#123; if pgrep -u $USERNAME -f $SERVICE &gt; /dev/null ; then echo &quot;$SERVICE is running... suspending saves&quot; as_user &quot;screen -p 0 -S $&#123;SCREENNAME&#125; -X eval &apos;stuff \&quot;say SERVER BACKUP STARTING. Server going readonly...\&quot;\015&apos;&quot; as_user &quot;screen -p 0 -S $&#123;SCREENNAME&#125; -X eval &apos;stuff \&quot;save-off\&quot;\015&apos;&quot; as_user &quot;screen -p 0 -S $&#123;SCREENNAME&#125; -X eval &apos;stuff \&quot;save-all\&quot;\015&apos;&quot; sync sleep 10 else echo &quot;$SERVICE is not running. Not suspending saves.&quot; fi&#125;mc_saveon() &#123; if pgrep -u $USERNAME -f $SERVICE &gt; /dev/null ; then echo &quot;$SERVICE is running... re-enabling saves&quot; as_user &quot;screen -p 0 -S $&#123;SCREENNAME&#125; -X eval &apos;stuff \&quot;save-on\&quot;\015&apos;&quot; as_user &quot;screen -p 0 -S $&#123;SCREENNAME&#125; -X eval &apos;stuff \&quot;say SERVER BACKUP ENDED. Server going read-write...\&quot;\015&apos;&quot; else echo &quot;$SERVICE is not running. Not resuming saves.&quot; fi&#125;mc_stop() &#123; if pgrep -u $USERNAME -f $SERVICE &gt; /dev/null ; then echo &quot;Stopping $SERVICE&quot; as_user &quot;screen -p 0 -S $&#123;SCREENNAME&#125; -X eval &apos;stuff \&quot;say SERVER SHUTTING DOWN IN 10 SECONDS. Saving map...\&quot;\015&apos;&quot; as_user &quot;screen -p 0 -S $&#123;SCREENNAME&#125; -X eval &apos;stuff \&quot;save-all\&quot;\015&apos;&quot; sleep 10 as_user &quot;screen -p 0 -S $&#123;SCREENNAME&#125; -X eval &apos;stuff \&quot;stop\&quot;\015&apos;&quot; sleep 7 else echo &quot;$SERVICE was not running.&quot; fi if pgrep -u $USERNAME -f $SERVICE &gt; /dev/null ; then echo &quot;Error! $SERVICE could not be stopped.&quot; else echo &quot;$SERVICE is stopped.&quot; fi&#125;mc_update() &#123; if pgrep -u $USERNAME -f $SERVICE &gt; /dev/null ; then echo &quot;$SERVICE is running! Will not start update.&quot; else as_user &quot;cd $MCPATH &amp;&amp; wget -q -O $MCPATH/versions --no-check-certificate https://launchermeta.mojang.com/mc/game/version_manifest.json&quot; if [ &quot;$1&quot; == &quot;snapshot&quot; ] ; then JSONVERSION=`cd $MCPATH &amp;&amp; cat versions | python -c &quot;exec(\&quot;import json,sys\nobj=json.load(sys.stdin)\nversion=obj[&apos;latest&apos;][&apos;snapshot&apos;]\nfor v in obj[&apos;versions&apos;]:\n if v[&apos;id&apos;]==version:\n print(v[&apos;url&apos;])\&quot;)&quot;` else JSONVERSION=`cd $MCPATH &amp;&amp; cat versions | python -c &quot;exec(\&quot;import json,sys\nobj=json.load(sys.stdin)\nversion=obj[&apos;latest&apos;][&apos;release&apos;]\nfor v in obj[&apos;versions&apos;]:\n if v[&apos;id&apos;]==version:\n print(v[&apos;url&apos;])\&quot;)&quot;` fi as_user &quot;cd $MCPATH &amp;&amp; wget -q -O $MCPATH/versions --no-check-certificate $JSONVERSION&quot; MC_SERVER_URL=`cd $MCPATH &amp;&amp; cat versions | python -c &apos;import json,sys;obj=json.load(sys.stdin);print(obj[&quot;downloads&quot;][&quot;server&quot;][&quot;url&quot;])&apos;` as_user &quot;rm $MCPATH/versions&quot; as_user &quot;cd $MCPATH &amp;&amp; wget -q -O $MCPATH/minecraft_server.jar.update --no-check-certificate $MC_SERVER_URL&quot; if [ -f $MCPATH/minecraft_server.jar.update ] ; then if `diff $MCPATH/$SERVICE $MCPATH/minecraft_server.jar.update &gt;/dev/null` ; then echo &quot;You are already running the latest version of $SERVICE.&quot; else as_user &quot;mv $MCPATH/minecraft_server.jar.update $MCPATH/$SERVICE&quot; echo &quot;Minecraft successfully updated.&quot; fi else echo &quot;Minecraft update could not be downloaded.&quot; fi fi&#125;mc_backup() &#123; mc_saveoff NOW=`date &quot;+%Y-%m-%d_%Hh%M&quot;` BACKUP_FILE=&quot;$BACKUPPATH/$&#123;WORLD&#125;_$&#123;NOW&#125;.tar&quot; echo &quot;Backing up minecraft world...&quot; #as_user &quot;cd $MCPATH &amp;&amp; cp -r $WORLD $BACKUPPATH/$&#123;WORLD&#125;_`date &quot;+%Y.%m.%d_%H.%M&quot;`&quot; as_user &quot;tar -C \&quot;$MCPATH\&quot; -cf \&quot;$BACKUP_FILE\&quot; $WORLD&quot; echo &quot;Backing up $SERVICE&quot; as_user &quot;tar -C \&quot;$MCPATH\&quot; -rf \&quot;$BACKUP_FILE\&quot; $SERVICE&quot; #as_user &quot;cp \&quot;$MCPATH/$SERVICE\&quot; \&quot;$BACKUPPATH/minecraft_server_$&#123;NOW&#125;.jar\&quot;&quot; mc_saveon echo &quot;Compressing backup...&quot; as_user &quot;gzip -f \&quot;$BACKUP_FILE\&quot;&quot; echo &quot;Done.&quot;&#125;mc_command() &#123; command=&quot;$1&quot;; if pgrep -u $USERNAME -f $SERVICE &gt; /dev/null ; then pre_log_len=`wc -l &quot;$MCPATH/logs/latest.log&quot; | awk &apos;&#123;print $1&#125;&apos;` echo &quot;$SERVICE is running... executing command&quot; as_user &quot;screen -p 0 -S $&#123;SCREENNAME&#125; -X eval &apos;stuff \&quot;$command\&quot;\015&apos;&quot; sleep .1 # assumes that the command will run and print to the log file in less than .1 seconds # print output tail -n $[`wc -l &quot;$MCPATH/logs/latest.log&quot; | awk &apos;&#123;print $1&#125;&apos;`-$pre_log_len] &quot;$MCPATH/logs/latest.log&quot; fi&#125;#Start-Stop herecase &quot;$1&quot; in start) mc_start ;; stop) mc_stop ;; restart) mc_stop mc_start ;; update) mc_stop mc_backup mc_update $2 mc_start ;; backup) mc_backup ;; status) if pgrep -u $USERNAME -f $SERVICE &gt; /dev/null ; then echo &quot;$SERVICE is running.&quot; else echo &quot;$SERVICE is not running.&quot; fi ;; command) if [ $# -gt 1 ] ; then shift mc_command &quot;$*&quot; else echo &quot;Must specify server command (try &apos;help&apos;?)&quot; fi ;; *) echo &quot;Usage: $0 &#123;start|stop|update|backup|status|restart|command \&quot;server command\&quot;&#125;&quot; exit 1 ;;esacexit 0]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[OpenSSH拒绝服务漏洞_CVE-2016-8858]]></title>
      <url>%2F2016%2F11%2F01%2Fopenssl_CVE-2016-8858%2F</url>
      <content type="text"><![CDATA[相关依赖 You will need working installations of Zlib and libcrypto (LibreSSL / OpenSSL) 下载相应源码 Dropbear临时替代SSH Dropbear https://matt.ucc.asn.au/dropbear/releases/ Zlib 1.1.4 or 1.2.1.2 or greater (earlier 1.2.x versions have problems) Zlib http://www.zlib.net/ libcrypto (LibreSSL or OpenSSL &gt;= 0.9.8f &lt; 1.1.0) OpenSSL https://www.openssl.org/source/ Note that because of API changes, OpenSSL 1.1.x is not currently supported.(2017/03/16更新) LibreSSL https://ftp.openbsd.org/pub/OpenBSD/LibreSSL/ OpenSSH https://ftp.openbsd.org/pub/OpenBSD/OpenSSH/portable/ 编译安装 Dropbear 123456tar xvf dropbear-2016.74.tar.bz2cd dropbear-2016.74/./configure --prefix=/opt/dropbear --enable-pammake &amp;&amp; make scp &amp;&amp; sudo make installsudo /opt/dropbear/bin/dropbearkey -t rsa -f /opt/dropbear/dropbear_rsa_host_key -s 4096sudo /opt/dropbear/sbin/dropbear -p 12598 -r /opt/dropbear/dropbear_rsa_host_key Zlib 1234tar -zxvf zlib-1.2.11.tar.gzcd zlib-1.2.11./configure --sharedmake &amp;&amp; make test &amp;&amp; sudo make install OpenSSl 12345tar xvf openssl-1.0.2k.tar.gzcd openssl-1.0.2k#./Configure --prefix=/usr shared./config --prefix=/usr sharedmake &amp;&amp; make test &amp;&amp; sudo make install OpenSSH 123456tar xvf openssh-7.4p1.tar.gzcd openssh-7.4p1./configure --prefix=/usr --sysconfdir=/etc/ssh --with-openssl-includes=/usr -with-ssl-dir=/usr/ssl --with-privsep-path=/var/myempty --with-privsep-user=sshd --with-zlib --with-ssl-engine --with-md5-passwords --with-pam --disable-etc-default-login &amp;&amp; \make &amp;&amp; \sudo mv /etc/ssh* /tmp/ &amp;&amp; \sudo make install]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[c语言连接数据库]]></title>
      <url>%2F2016%2F10%2F16%2Fc_mysql%2F</url>
      <content type="text"><![CDATA[c语言连接数据库执行sql语句 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#if defined(_WIN32) || defined(_WIN64) //为了支持windows平台上的编译#include &lt;windows.h&gt;#endif#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &quot;mysql.h&quot; #define SELECT_QUERY &quot;select username from tbb_user where userid = %d&quot; int main(int argc, char **argv) //char **argv 相当于 char *argv[]&#123; MYSQL mysql,*sock; //定义数据库连接的句柄，它被用于几乎所有的MySQL函数 MYSQL_RES *res; //查询结果集，结构类型 MYSQL_FIELD *fd ; //包含字段信息的结构 MYSQL_ROW row ; //存放一行查询结果的字符串数组 char qbuf[160]; //存放查询sql语句字符串 if (argc != 2) &#123; //检查输入参数 fprintf(stderr,&quot;usage : mysql_select &lt;userid&gt;\n\n&quot;); exit(1); &#125; mysql_init(&amp;mysql); if (!(sock = mysql_real_connect(&amp;mysql,&quot;localhost&quot;,&quot;dbuser&quot;,&quot;dbpwd&quot;,&quot;9tmd_bbs_utf8&quot;,0,NULL,0))) &#123; fprintf(stderr,&quot;Couldn&apos;t connect to engine!\n%s\n\n&quot;,mysql_error(&amp;mysql)); perror(&quot;&quot;); exit(1); &#125; sprintf(qbuf,SELECT_QUERY,atoi(argv[1])); if(mysql_query(sock,qbuf)) &#123; fprintf(stderr,&quot;Query failed (%s)\n&quot;,mysql_error(sock)); exit(1); &#125; if (!(res=mysql_store_result(sock))) &#123; fprintf(stderr,&quot;Couldn&apos;t get result from %s\n&quot;, mysql_error(sock)); exit(1); &#125; printf(&quot;number of fields returned: %d\n&quot;,mysql_num_fields(res)); while (row = mysql_fetch_row(res)) &#123; printf(&quot;Ther userid #%d &apos;s username is: %s\n&quot;, atoi(argv[1]),(((row[0]==NULL)&amp;&amp;(!strlen(row[0]))) ? &quot;NULL&quot; : row[0])) ; puts( &quot;query ok !\n&quot; ) ; &#125; mysql_free_result(res); mysql_close(sock); exit(0); return 0;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ORACLE 11G R2静默安装，配置]]></title>
      <url>%2F2016%2F10%2F05%2Foracle_11gr2_silent_install%2F</url>
      <content type="text"><![CDATA[ORACLE 11G R2静默安装，配置目录 准备工作 开始安装 安装后工作 建库 配置监听 测试 准备工作1.依赖性准备 #yum install make gcc binutils gcc-c++ compat-libstdc++ elfutils-libelf-devel elfutils-libelf-devel-static ksh libaio libaio-devel numactl-devel sysstat unixODBC unixODBC-devel pcre-devel glibc.i686 2.用户和组准备 #groupadd oinstall #groupadd dba #useradd -g oinstall -G dba -d /home/oracle oracle #passwd oracle //设置oracle密码 3.目录准备及权限调整 #mkdir -p /export/servers/oracle/11.2.0 //数据库系统安装目录 #mkdir /export/data/oradata //数据库数据安装目录 #mkdir /export/data/oradata_back //数据备份目录 #mkdir /home/oracle/inventory //清单目录 #chown -R oracle:oinstall /export/servers/oracle #chown -R oracle:oinstall /home/oracle/inventory #chown -R oracle:oinstall /export/data #chomod -R 775 /export/servers/oracle #chomod -R 775 /export/data 以上工作可通过招待 pre-install.sh 脚本完成. 4.内核参数调整 #vim /etc/sysctl.conf 在文件最后增加 fs.aio-max-nr = 1048576 fs.file-max = 6553600 kernel.shmall = 2097152 kernel.shmmax = 2147483648 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 1024 65000 net.core.rmem_default = 262144 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048586 保存文件。 #/sbin/sysctl -p //让参数生效 5.用户的限制文件修改 #vim /etc/security/limits.conf 在文件后增加 oracle soft nproc 2047 oracle hard nproc 16384 oracle soft nofile 1024 oracle hard nofile 65536 oracle soft stack 10240 保存文件。 修改/etc/pam.d/login文件，增加如下： session required /lib64/security/pam_limits.so //64为系统，千万别写成/lib/security/pam_limits.so，否则导致无法登录 session required pam_limits.so 修改/etc/profile,增加： if [ $USER = &quot;oracle&quot; ]; then if [ $SHELL = &quot;/bin/ksh&quot; ]; then ulimit -p 16384 ulimit -n 65536 else ulimit -u 16384 -n 65536 fi fi 6.oracle安装包准备 下载并解压安装包到 /home/oracle/database 开始安装1.打开另外一个终端，用oracle用户登录 2.复制并修改应答文件 复制应答文件 $cp -R /home/oracle/database/response/db_install.rsp /home/oracle/database/response/my_db_install.rsp #复制一份模板文件，以便改错后回滚 修改应答文件 $vim /home/oracle/database/response/my_db_install.rsp,按实际情况修改以下项 oracle.install.option=INSTALL_DB_SWONLY ORACLE_HOSTNAME=oracle11g.jd.com UNIX_GROUP_NAME=oinstall INVENTORY_LOCATION=/home/oracle/inventory/ ORACLE_HOME=/export/servers/oracle/11.2.0 ORACLE_BASE=/export/servers/oracle oracle.install.db.InstallEdition=EE oracle.install.db.isCustomInstall=false oracle.install.db.DBA_GROUP=dba oracle.install.db.OPER_GROUP=dba DECLINE_SECURITY_UPDATES=true 修改好的应答文件，保存在 /vagrant/zhs16gbk/db_install.rsp 文件中，可直接使用。 3.根据应答文件，开始安装 $ sudo su - oracle $ cd /home/oracle/database/ $ ./runInstaller -silent -responseFile /vagrant/zhs16gbk/db_install.rsp 4.按提示切换到root用户的终端，依次执行脚本 #/home/oracle/inventory/orainstRoot.sh #/opt/oracle/11.2.0/root.sh 脚本位置会提示 5.切换到oracle用户的终端，敲”回车“，完成安装 6.修改oracle用户环境变量 $vim ~/.bash_profile 添加以下内容 User specific environment and startup programsexport ORACLE_SID=orclexport ORACLE_BASE=/app/server/oracleexport ORACLE_HOME=$ORACLE_BASE/product/11.2.0/db_1export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/libPATH=$PATH:$ORACLE_HOME/bin 7.执行$source ~/.bash_profile 刷新环境变量 安装后工作建库1.复制并修改建库应答文件 复制应答文件 $cp -R /home/oracle/database/response/dbca.rsp /home/oracle/database/response/my_dbca.rsp 修改应答文件 $vim /home/oracle/database/response/my_dbca.rsp 修改以下项 OPERATION_TYPE = &quot;createDatabase&quot; GDBNAME = &quot;orcl11g&quot; SID = &quot;orcl&quot; SYSPASSWORD = &quot;OraPwd11&quot; SYSTEMPASSWORD = &quot;OraPwd11&quot; DATAFILEDESTINATION = /app/data/oradata RECOVERYAREADESTINATION = /app/data/oradata_back SYSDBAUSERNAME = &quot;system&quot; SYSDBAPASSWORD = &quot;OraPwd11&quot; #以上2项可选 INSTANCENAME = &quot;orcl11g&quot; CHARACTERSET = &quot;ZHS16GBK&quot; #按需求设置，建议使用UTF-8 NATIONALCHARACTERSET= &quot;&quot; #可选 &quot;UTF8&quot; or &quot;AL16UTF16&quot; 建议UTF-8 TOTALMEMORY = &quot;5120&quot; #Oracle使用的最大内存，单位M建库 修改好的应答文件，保存在 /vagrant/zhs16gbk/dbca.rsp 文件中，可直接使用。 2.使用dbca静默建库 $dbca -silent -responseFile /vagrant/zhs16gbk/dbca.rsp 配置监听1.使用netca静默方式创建监听 $netca /silent /responsefile /vagrant/zhs16gbk/netca.rsp 执行完成会在 $ORACLE_HOME/network/admin目录下生成sqlnet.ora和listener.ora两个文件。 2.注册sid vim $ORACLE_HOME/network/admin/listener.ora 在 LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) (ADDRESS = (PROTOCOL = TCP)(HOST = localhost)(PORT = 1521)) ) ) 之前添加以下内容： SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = orcl) (ORACLE_HOME = /app/server/oracle/product/11.2.0/db_1) (PROGRAM = extproc) ) ) 3.执行$lsnrctl reload重启监听 4.编辑 /etc/oratab 把 orcl11g:/export/servers/oracle/11.2.0:N的‘N’，改为‘Y’，这样就可以通过dbstart启动此实例，也可以通过dbshut关闭此实例了。 测试1.查看监听状态 $lsnrctl status 类似以下返回，说明监听状态正常 Service &quot;ORCL&quot; has 1 instance(s). Instance &quot;orcl11g&quot;, status UNKNOWN, has 1 handler(s) for this service... Service &quot;db1&quot; has 1 instance(s). Instance &quot;orcl11g&quot;, status READY, has 1 handler(s) for this service... Service &quot;orcl11gXDB&quot; has 1 instance(s). Instance &quot;orcl11g&quot;, status READY, has 1 handler(s) for this service... 2.sqlplus连接测试 $export $ORACLE_SID=orcl11g $sqlplus / as sysdba 正常登陆说明实例正常启动。 自启动脚本加入 /etc/init.d/oracledb 文件： #!/bin/sh -e chkconfig: 3 56 10description: Oracle 11g custom start/stop scriptDAEMON=oracleORACLE_HOME=/app/server/oracle/product/11.2.0/db_1ORACLE_OWNER=oracle restart() { stop start} case $1 in ‘start’) su - ${ORACLE_OWNER} -c “${ORACLE_HOME}/bin/lsnrctl start” su - ${ORACLE_OWNER} -c “${ORACLE_HOME}/bin/dbstart ${ORACLE_HOME}” #su - ${ORACLE_OWNER} -c &quot;${ORACLE_HOME}/bin/emctl start dbconsole&quot; #su - ${ORACLE_OWNER} -c &quot;${ORACLE_HOME}/bin/isqlplusctl start&quot; ;; &apos;stop&apos;) #su - ${ORACLE_OWNER} -c &quot;${ORACLE_HOME}/bin/isqlplusctl stop&quot; #su - ${ORACLE_OWNER} -c &quot;${ORACLE_HOME}/bin/emctl stop dbconsole&quot; su - ${ORACLE_OWNER} -c &quot;${ORACLE_HOME}/bin/dbshut ${ORACLE_HOME}&quot; su - ${ORACLE_OWNER} -c &quot;${ORACLE_HOME}/bin/lsnrctl stop&quot; ;; restart) restart ;; *) echo &quot;Usage: $0 {start|stop}&quot; exit ;; esac exit $? 加入自动启动: $ sudo chkconfig –add oracledb 文档约定#开头的命令 说明需要使用root用户执行 $开头的命令 说明需要用oracle用户执行]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[oracle error]]></title>
      <url>%2F2016%2F09%2F11%2Foracle_error%2F</url>
      <content type="text"><![CDATA[In this DocumentPurposeTroubleshooting Steps Section I: Steps to approach ORA-12518/TNS-12518 Error: Section II: Commonly Known Errors:Error: 32: Broken pipeError: 11: Resource temporarily unavailableError: 12: Not enough space Error: Connection Pooling limit reachedError: 2: No such file or directoryError: 24: Too many open files Section III: Errors Specific to WindowsError: 233: Unknown errorError: 54: Unknown error123456789101112131415161718ReferencesAPPLIES TO:Oracle Net Services - Version 10.1.0.2 to 11.2.0.3 [Release 10.1 to 11.2]Information in this document applies to any platform.PURPOSEThis article discusses about how to approach ORA-12518/TNS-12518 and troubleshoot it for the resolution.TROUBLESHOOTING STEPSSection I: Steps to approach ORA-12518/TNS-12518 Error: ORA-12518/TNS-12518 indicates a problem while listener hands off the client connection to the server process or dispatcher process.TNS-12518 is logged in the listener log. The client might receive ORA-12518 or some other disconnection errors like ORA-12537. Once TNS-12518 is noted in the listener log, follow the below steps to approach and resolve this error. Let us have a small discussion about how actually database connections are made:In Dedicated mode, database client contacts listener and supplies the SERVICE NAME of the database. Then listener spawns a dedicated server process and hands off the client connection to this dedicated server process. TNS-12518 indicates a problem while handing off the client connection to the server process.In Shared Server mode, database client contacts listener and supplies the SERVICE NAME of the database. Then listener hands off the client connection to one of the dispatcher configured for that service. TNS-12518 indicates a problem while handing off the client connection to the dispatcher server process.Though this error is logged in the listener log, the listener is just the messenger, ORA-12518/TNS-12518 is mostly related to RDBMS and OS resources. Step 1. Is listener version compatible to the database1234567Check if you are using compatible listener version for your database version. If the database is 8i then use 8i or 9i listeners only. 10g listeners are not compatible to work with 8i databases. For 9i databases, 9i or 10g listeners can be used. For 10g databases, only 10g listeners can be used. The general rule is that use the higher version of the listener when there is a version mismatch between database and the listener. Step 2. Gather more information from listener log123456789101112131415161718The first place you would look for the TNS-12518 error is the listener log. Usually the listener log would be located under $ORACLE_HOME/network/log directory. You can use &apos;lsnrctl status&apos; command output to look for the location of the listener log file.$lsnrctl status - - - - - - Listener Parameter File /ora10g/home_ora10g/network/admin/listener.ora Listener Log File /ora10g/home_ora10g/network/log/listener.log - - - - - -listener log gives the complete error stack and the database service name to which the client tried to connect to.19-SEP-2007 13:55:34 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=__jdbc__)(USER=))(SERVICE_NAME=test.oracle.com)) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.10.10.3)(PORT=36030)) * establish * test.oracle.com * 12518 TNS-12518: TNS:listener could not hand off client connection TNS-12547: TNS:lost contact TNS-12560: TNS:protocol adapter error TNS-00517: Lost contact Linux Error: 32: Broken pipeIn the above example, listener log shows the complete error stack, the bottom error being 32 is the OS error. It also shows that the jdbc client from IP 10.10.10.3 has tried to connect to the database service &apos;test.oracle.com&apos; and failed with the error 12518.Look for the lowest error in the stack. That is the error we have to concentrate on and try to resolve it. In the above example, the lower error is &apos;Linux Error: 32: Broken pipe&apos;. Step 3. Is service handlers in blocked state1234567891011121314151617Check if the handlers are in blocked state. Check the output of the &apos;lsnrctl services&apos;. Examine the status information under the database service name. From the listener log you would know which database service was affected by the 12518 error, now with the output of the &apos;lsnrctl services&apos; under that service name gather more information.Service &quot;test.oracle.com&quot; has 1 instance(s). Instance &quot;db10g&quot;, status READY, has 2 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:9 refused:0 state:ready LOCAL SERVER &quot;D000&quot; established:10 refused:0 current:0 max:972 state:ready DISPATCHER (ADDRESS=(PROTOCOL=tcp)(HOST=oid.mohan.com)(PORT=33487))The highlighted state should be in &apos;ready&apos; state for the connection to be successful. If the state is in &apos;blocked&apos; then the connection are not possible. The state of a handler could be in blocked state in the following scenario: i. The database parameter processes reached its value. ii. The database is in the process of startup or shutting down. In shared server mode, the number of dispatchers should be set according to the load that you expect. &apos;lsnrctl services&apos; output shows the maximum number(max:997) of connections that the dispatcher would accept and the number connections refused (refused:0) by this dispatcher. If any connections refused by the dispatcher, then consider increasing the number of dispatchers. If you are using PFILE edit init.ora and increase the dispatchers parameter. If you are using SPFILE you can dynamically increase the dispatchers parameter by the &apos;alter system set&apos; command. Step 4. Is local BEQ connection successful123456789101112Check if local BEQ connection to the database works fine. It also verifies if the database is up and in good condition to accept the connection. If the database is down or in a hung state then a connection request to the database by the listener will not be possible. Connect to the database server via telnet or ssh and check if a local bequeath SQL*Plus connection works. In other words, issue:sqlplus username/password [Enter]This connection bypasses the listener and directly connects to the database via the BEQ (bequeath) protocol. If this fails, then the TNS-12518 listener error is simply a result of the database issue. One such error is:ORA-12560: TNS:protocol adapter errorA possible cause for this error on Microsoft Windows servers, is that the Windows Database Service has not yet been created (common when creating a &quot;standby&quot; instance).Resolution for this would be to create the Windows Service first by using the &quot;oradim&quot; command (see the Database Admin guide for details on oradim and service creation). Step 5. Is number of processes reached its limit1234567891011121314151617If local BEQ is successful, check the below querySQL&gt; select * from v$resource_limit; RESOURCE_NAME CURRENT_UTILIZATION MAX_UTILIZATION INITIAL_AL LIMIT_VALU -------------------- ------------------- --------------- ---------- ---------- processes 249 250 250 250 sessions 54 82 280 280 - - - - - -- - - - - - Verify if the processes or sessions reached its limit value. If these database parameters reached its limit value, then consider increasing it accordingly. In the above example, the processes parameter has been set to 250. It&apos;sMAX_UTILIZATION has reached the limit value of 250, so the processes parameter should be increased further to accomodate the number of incoming connections. Edit the init.ora and set the processes parameter to a higher value. By default, if you just increase the processes it is enough, the sessions value would automatically be increased.Check the alert.log for a corresponding error such as &quot;ksvcreate&quot; process failed, etc. Check timestamp against listener.log timestamps for causal relationship. Step 6. Is OS kernal parameters configured for optimum12345678Database is operated by a single user, normally it would be &apos;oracle&apos; user. At the Operating System level, there is a limit for the number of process spawned by a user. And also there is a limit for the total number of process running on the entire OS. The Oracle Database and the newly spawned processes would be owned by the &apos;oracle&apos; user. And so make sure that these values are set accordingly.On Unix these values are configured through the configurable OS kernal parameters and is specific to Operating Systems. You will have check your corresponding OS documentation for your OS. For example for HP-UX the configurable kernal parameters are, maxuprc Maximum number of processes for each non-root user nproc Maximum number of processes on the system Step 7. Does alert log have any errors1234567891011121314151617181920212223242526272829303132333435Look in alert log and look for any errors related to memory or process during the time the error TNS-12518 occurred in the listener log. If the alert log has any memory related errors, there there is a potential memory resource issue at the OS level. OS memory issues can be addressed by the below: i. Make sure that the OS has been configured with the enough Swap memory. In case of Windows it is called as Virtual Memory. ii. Reduce the size of SGA, thus the newly spawned server process will have some more system memory available. iii. Reduce the PGA size, so that the newly spawned server process would occupy less memory. iv. If you are in DEDICATED mode, try switching to MTS mode. To address memory issue for 32-bit Windows: Refer Note 371983.1If there are any memory or process related error in the alert log during the time the TNS-12518 is logged in the listener log, then those errors in the alert log should be focused on and should be solved at first. Because, the errors in the alert log is the base error for the TNS-12518 in the listener log. However, the errors in the alert logs are not being discussed in this article, they are out of the scope of this article.Step 8. If using a statically defined SID_DESC in the listener.ora file for your sid, ensure that it is configured properly. A common mistake is to include a (PROGRAM=EXTPROC) parameter: (SID_LIST= (SID_DESC = (GLOBAL_DBNAME = ORCL.oracle.com) (SID_NAME = ORCL) (PROGRAM=extproc) (ORACLE_HOME = D:\oracle\product\10.2.0\db_1)))This misconfiguration occurs when the PLSExtproc SID_DESC is copied, pasted and edited in the listener.ora file. The inclusion of the PROGRAM line will cause an ORA-12518 to be returned to the client. Here&apos;s the corrected SID_DESC for our example SID: (SID_LIST= (SID_DESC = (GLOBAL_DBNAME = ORCL.oracle.com) (SID_NAME = ORCL) (ORACLE_HOME = D:\oracle\product\10.2.0\db_1)))Section II: Commonly Known Errors:This section lists some of the known and reported errors. It is also recommended that you refer the Section I above for a generic troubleshooting approach to the error TNS-12518.Below shows example error stack that can be found in the listener log. The last line in the error stack shows the actual operating system name. Depending on the OS, only the operating system name would be different. For example, if you encounter error 32: Broken pipe, according to the OS, the last line in the error stack would be different only by the OS name, as shown below.Solaris Error: 32: Broken pipe HPUX Error: 32: Broken pipe Linux Error: 32: Broken pipe Error: 32: Broken pipe1234567891011121314151617181920Error stack in listener log: TNS-12518: TNS:listener could not hand off client connection TNS-12547: TNS:lost contact TNS-12560: TNS:protocol adapter error TNS-00517: Lost contact IBM/AIX RISC System/6000 Error: 32: Broken pipe Cause: The error 32 indicates the communication has been broken while the listener is trying to hand off the client connection to the server process or dispatcher process. Action: 1. One of reason would be processes parameter being low, and can be verified by the v$resource_limit view. 2. In Shared Server mode, check the &apos;lsnrctl services&apos; output and see if the dispatcher has refused any connections, if so, then consider increasing the number of dispatchers. 3. Check the alert log for any possible errors. 4. Memory resource is also another cause for this issue. Check the swap, memory usage of the OS.5. If RAC/SCAN or listener is running in separate home, check the following note:Note: 1069517.1 ORA-12537 or TNS-12518 if Listener (including SCAN Listener) and Database are Owned by Different OS User Error: 11: Resource temporarily unavailable1234567891011121314Error stack in listener log: TNS-12518: TNS:listener could not hand off client connection TNS-12549: TNS:operating system resource quota exceeded TNS-12560: TNS:protocol adapter error TNS-00519: Operating system resource quota exceeded IBM/AIX RISC System/6000 Error: 11: Resource temporarily unavailable Cause: As the error indicates operating system resource has exceeded. Action: 1. Increase the appropriate OS kernal parameters for &apos;maximum number of processes allowed per user&apos;. For example for HP-UX the parameters are maxuprc and nproc. Error: 12: Not enough space1234567891011121314151617181920212223Error stack in listener log: TNS-12518: TNS:listener could not hand off client connection TNS-12549: TNS:operating system resource quota exceeded TNS-12560: TNS:protocol adapter error TNS-00519: Operating system resource quota exceeded IBM/AIX RISC System/6000 Error: 12: Not enough space Cause: This is a memory related issue. The error indicates that there is not enough memory available to spawn and hand off the client connections. Typical problems are: - Out of system memory / swap - Out of process slots in the process table - Streams resources depleted - Out of File Handles - sga memory usage Action: 1. Check in the alert log for any possible memory related error. 2. Increase swap/Virtual memory if possible the available memory. 3. SGA and PGA can be reduced to address the memory consumption. 4. MTS mode can be used to reduce the amount of process and memory consumption. Error: Connection Pooling limit reached12345678Error stack in listener log: TNS-12518 TNS:listener could not hand off client connection TNS-12564 TNS:connection refused TNS-12602 TNS: Connection Pooling limit reached Action: 1. Try increasing initial number of dispatchers. Error: 2: No such file or directory123456789101112131415161718Error stack in listener log: TNS-12518: TNS:listener could not hand off client connection TNS-12560: TNS:proto adapter error TNS-00530: Proto adapter error 32-bit Windows Error: 2: No such file or directory Error Description: ERROR_FILE_NOT_FOUND 2 The system cannot find the file specified. Cause: This indicates the database service is not actually available Action: 1.Verify if the intended database really up and accepting local BEQ connections. Error: 24: Too many open files12345678910111213141516171819202122Error stack in listener log: TNS-12518: TNS:listener could not hand off client connection TNS-12560: TNS:protocol adapter error TNS-00530: Protocol adapter error Linux Error: 24: Too many open filesor TNS-12518: TNS:listener could not hand off client connection TNS-12560: TNS:protocol adapter error TNS-00530: Protocol adapter error Solaris Error: 24: Too many open filesError Description: Out of file descriptorsCause:Can be caused by the following unpublished defect:BUG 13078786 - LISTENER GOES DOWN SUDDENLY W/ LINUX ERROR: 32: BROKEN PIPEAction:See Note 1527483.1 11.2 : ORA-12518 Listener Hangs and Reports &quot;Too Many Open Files&quot; Use prescribed workaround OR apply one-off patch to your environment if available. Section III: Errors Specific to Windows123It is also recommended that you refer the Section I above for a generic troubleshooting approach to the error TNS-12518.This section briefly describes about the errors that are encountered on Windows Operating System. TNS-12518 most commonly occurs on 32-bit OS due to its memory constraint, however TNS-12518 can occur on 64-bit OS as well. See Note 873752.1 for more information on Windows memory addressing and the 3GB switch. Error: 233: Unknown error123456789101112131415161718Error stack in listener log: TNS-12518: TNS:listener could not hand off client connection TNS-12560: TNS:protocol adapter error TNS-00530: Protocol adapter error 32-bit Windows Error: 233: Unknown error Error Description: ERROR_PIPE_NOT_CONNECTED 233 No process is on the other end of the pipe. Cause: The communication has been broken while the listener is trying to hand off the client connection to the server process or dispatcher process. Action: Refer Note 371983.1 Error: 54: Unknown error123456789101112131415161718192021Error stack in listener log: TNS-12518: TNS:listener could not hand off client connection TNS-12571: TNS:packet writer failure TNS-12560: TNS:protocol adapter error TNS-00530: Protocol adapter error 32-bit Windows Error: 54: Unknown error Error Description: ERROR_NETWORK_BUSY 54 0x36 The network is busy. Cause: This indicates a bottleneck at the network layer(TCP/IP). Action: 1.Try increasing dispatchers and shared servers. 转载ROUBLESHOOTING GUIDE TNS-12518 TNS listener could not hand off client connection (文档ID 550859.1)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[DB2常用命令]]></title>
      <url>%2F2016%2F09%2F06%2Fdb2%2F</url>
      <content type="text"><![CDATA[启动实例(db2inst1)：实例相当于informix中的服务db2start 停止实例(db2inst1)：db2stop 列出所有实例(db2inst1)db2ilist 列出当前实例：db2 get instance 察看示例配置文件：db2 get dbm cfg|more 更新数据库管理器参数信息：db2 update dbm cfg using para_name para_value 创建数据库：db2 create db test 察看数据库配置参数信息db2 get db cfg for test|more 更新数据库参数配置信息db2 update db cfg for test using para_name para_value 删除数据库：db2 drop db test 连接数据库db2 connect to test 列出所有表空间的详细信息。db2 list tablespaces show detail 列出容器的信息db2 list tablespace containers for tbs_id show detail 创建表：db2 ceate table tb1(id integer not null,name char(10)) 列出所有表db2 list tables 插入数据：db2 insert into tb1 values(1,’sam’); db2 insert into tb2 values(2,’smitty’); 查询数据：db2 “select * from tb1” 删除数据：db2 delete from tb1 where id=1 创建索引：db2 create index idx1 on tb1(id); 创建视图：db2 create view view1 as select id from tb1 查询视图：db2 select * from view1 节点编目db2 catalog tcp node node_name remote server_ip server server_port 察看端口号db2 get dbm cfg|grep SVCENAME 节点的附接db2 attach to node_name 察看本地节点db2 list node direcotry 节点反编目db2 uncatalog node node_name 数据库编目db2 catalog db db_name as db_alias at node node_name 察看数据库的编目db2 list db directory 连接数据库db2 connect to db_alias user user_name using user_password 数据库反编目db2 uncatalog db db_alias 导出数据db2 export to myfile of ixf messages msg select * from tb1 导入数据db2 import from myfile of ixf messages msg replace into tb1 导出数据库的所有表数据db2move test export 生成数据库的定义db2look -d db_alias -a -e -m -l -x -f -o db2look.sql 创建数据库db2 create db test1 生成定义db2 -tvf db2look.sql 导入数据库所有的数据db2move db_alias import 重组检查db2 reorgchk 重组表tb1db2 reorg table tb1 更新统计信息db2 runstats on table tb1 备份数据库testdb2 backup db test 恢复数据库testdb2 restore db test 拥有实例的所有程序列表db2 list application 断开数据库连接,同时退出db2 terminate 查看数据表结构db2 “describe select * from ggwdxtcs” 启动命令界面db2cmd 查看帮助db2 ? * 连接数据库db2 connect to user using 查看数据库实例db2ilist 停止数据库应用db2 force applications all 查看表空间db2 list tablespaces show detail 查看表是否有记录db2 select count(*) from 从文本导入到数据库表中db2 import from #####*.ixf of ixf modified by forcein commitcount 1000 insert into 查看sql语句错误解释db2 ? sql########## ##########为四位出错编码，不足位前补0 db2 ? “sqlstate” db2 ? sqlstate=42884 db2 “select * from syscat.functions” |grep –i rtrim db2 “select * from syscat.indexes” 表增加列db2 alter table 表名 add column 字段名 varchar(4)(字段类型） 修改表里的字段db2 update 表名 set 字段名=&apos;xxx&apos; where .....]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[sqlplus 安装]]></title>
      <url>%2F2016%2F07%2F25%2Foracle_sqlplus%2F</url>
      <content type="text"><![CDATA[Oracle数据库软件十分庞大，数据库引擎有好几个G。通常情况下，我们的使用方式是安装一个Oracle数据库在服务器机器上，在客户端通过PL/SQL Developer、sqlplus等工具操作服务器上的数据，当然Oracle 10g后，OEM(企业管理器)已经是WEB版了，在浏览器中也可以同样操作数据库。 Windows 下Oracle Instant Client 的安装Windows下客户端工具 PL/SQL Developer 使用得最多，Linux下，我喜欢直接使用sqlplus。不论使用哪种工具，都需要在客户端机器上安装Oracle客户端工具，安装以下三种软件均可连接Oracle服务器： (a) Oracle 数据库引擎 (b) Oracle Client (c) Oracle Instant Client 其中前两种占硬盘空间大，并且安装也相对繁琐，我一般喜欢采用第三种方式，因此，下面介绍 Oracle Instant Client 的安装： Windows 下Oracle Instant Client 的安装 Oracle Instant Client 下载 进入Oracle官网首页，单击首页中的downloads链接，在新页面中选择 Database —&gt; Instant Client，进入 Instant Client Downloads 页，选择相应版本下载。 Oracle 中文网站 我下载的软件包是：basic、sqlplus. 注意，必须下载basic或者basiclite其中之一，若需要做 OCI / OCCI 开发，还需下载 sdk. Oracle Instant Client 安装 安装很简单，只需直接解压两个包即可，将两个包解压到同一目录下 例如解压到目录 D:\instantclient-10.2.0.3-win32\下。 最后目录结构是：D:\instantclient-10.2.0.3-win32\instantclient_10_2，instantclient_10_2目录下就是解压后的 basic 和 sqlplus. 创建数据库连接文件在 D:\instantclient-10.2.0.3-win32\instantclient_10_2 目录下创建文件夹 admin，在 admin 目录下创建文件 tnsnames.ora，根据数据库连接输入以下类似内容 1234567891011# tnsnames.ora Network Configuration File: /opt/oracle_11g_R2_x64/product/11.2.0.1.0/db_1/network/admin/tnsnames.ora # Generated by Oracle configuration tools. ORCL = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.232.133)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = orcl) ) ) 该文件和数据库服务器中的文件内容类似，其作用是配置 sqlplus 和 PL/SQL Developer 中连接时的连接字符串。大家都知道该文件的作用，不必赘述。 配置Windows环境变量 ORACLE_HOME=D:\instantclient-10.2.0.3-win32\instantclient_10_2 Path=%ORACLE_HOME%; xxxxxx ===&gt; 作用是在命令行中可以找到 sqlplus 等命令，在运行sqlplus时加载相关库 TNS_ADMIN=%ORACLE_HOME%\admin ===&gt; 作用是在sqlplus等工具中连接数据库时能找到 tnsnames.ora中的连接符 NLS_lANG=SIMPLIFIED CHINESE_CHINA.ZHS16GBK ===&gt; 设置客户端的字符集 完成，测试! 经过以上步骤后，Oracle Instant Client 安装完毕，在命令行中可以使用命令连接服务器. 1234567C:\Users\kebyn&gt;sqlplus /nolog SQL*Plus: Release 10.2.0.3.0 - Production on 星期二 1月 10 10:52:53 2012 Copyright (c) 1982, 2006, Oracle. All Rights Reserved. SQL&gt; conn scott/tiger@orcl ===&gt; 使用到 %TNS_ADMIN% 下 tnsnames.ora中的连接符ORCL Linux 下 Oracle Instant Client 的安装 下载 Linux 下的 Oracle Instant Client有rpm包和zip包两种，下载任意一种即可，这里以下载的 zip包为例 oracle-instantclient11.2-basic-11.2.0.1.0-1.x86_64.zip oracle-instantclient11.2-sqlplus-11.2.0.1.0-1.x86_64.zip oracle-instantclient11.2-sdk-11.2.0.1.0-1.x86_64.zip 解压安装文件被解压到目录 instantclient_11_2 下 创建数据库连接文件123cd instantclient_11_2mkdir network/adminvim network/admin/tnsnames.ora 1234567891011# tnsnames.ora Network Configuration File: /sdb1/oracle/11gR2_database_X64/product/11.2.0.1.0/db_1/network/admin/tnsnames.ora # Generated by Oracle configuration tools. ZKL = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = glnode04)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = zkl) ) ) 配置环境变量1vim ~/.bashrc 12345export ORACLE_HOME=/root/linux-11.2.0.1.0-1.x86_64/instantclient_11_2export PATH=$ORACLE_HOME:$PATH export TNS_ADMIN=$ORACLE_HOME/network/admin export LD_LIBRARY_PATH=$ORACLE_HOME:$LD_LIBRARY_PATH export NLS_LANG=&apos;simplified chinese_china.ZHS16GBK&apos; 注意要配置LD_LIBRARY_PATH 变量，sqlplus等程序运行时需要加载相应库，若不配置，则运行时会出现如下错误：123Error 6 initializing SQL*PlusSP2-0667: Message file sp1&lt;lang&gt;.msb not foundSP2-0750: You may need to set ORACLE_HOME to your Oracle software directory 配置完毕后1source ~/.bashrc 完成，测试!123456789[root@kebyn instantclient_11_2]# sqlplus /nologSQL*Plus: Release 11.2.0.1.0 Production on 星期二 1月 10 11:14:31 2012Copyright (c) 1982, 2009, Oracle. All rights reserved.SQL&gt; conn zkl/zkl@zkl已连接。SQL&gt; 在Oracle中，我们会遇到下面一系列的十分重要的参数。同时他们的含义也常常让我们混淆。这些参数有：ORACLE_SID, SID, INSTANCE_NAME, SERVICE_NAME, SERVICES_NAMES, DB_NAME, GLOBAL_DBNAME, SID_NAME，以及网络服务名(net service name)，实例服务名(instance service name)等。 ORACLE_SID 与 SID 和 INSTANCE_NAME 以及 SID_NAMEORACLE_SID：即ORACLE System IDentifier,它是一个环境变量。我们一般在oracle用户的home目录中的.bash_profile中进行定义，一般该文件包含下面一行：12 grep ORACLE_SID .bash_profileexport ORACLE_SID=orcl 其作用就是：在我们使用在sqlplus工具中startup启动数据库时，OS就是利用这个环境变量来fork创建构成Oracle实例的各个进程，以及来命名一些文件的名字。 下面的命令的执行必须要有环境变量ORACLE_SID:1SQL&gt; startup 那么我们的环境变量ORACLE_SID应该设置成什么值呢？应该是：我们想要startup哪个Oracle实例，就应该将ORACLE_SID设置成哪个实例的SID： Oracle server由Oracle实例和Oracle数据库两者共同组成。 很显然地，我们想要startup哪个Oracle实例，就应该将环境变量ORACLE_SID设置成哪个SID。 SID唯一地标识一个Oracle实例，而ORACLE_SID启动该实例，启动之后我们得到一个Oracle实例，这个实例有一个名字：INSTANCE_NAME。SID==&gt;&gt;ORACLE_SID==&gt;&gt;INSTANCE_NAME这三者是一致的，是完全相同的。 同时这个实例向外提供服务，所以又有一个SERVICE_NAME。 而SID_NAME出现在lisnter.ora文件中：12345678910111213141516171819202122232425[oracle@localhost oracle]$ cat listener.ora# listener.ora Network Configuration File: /u01/app/oracle/product/10.2.0/db_1/network/admin/listener.ora# Generated by Oracle configuration tools.SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = PL***tProc) (ORACLE_HOME = /u01/app/oracle/product/10.2.0/db_1) (PROGRAM = extproc) ) (SID_DESC = (SID_NAME = orcl) (ORACLE_HOME = /u01/app/oracle/product/10.2.0/db_1) (GLOBAL_DBNAME = orcl) ) )LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = localhost)(PORT = 1521)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) ) ) lisnter.ora中的SID_NAME的值必须与SID的值一致。通过lisnter.ora中的SID_NAME和GLOBAL_DBNAME两个参数以及客户端的tnsnames.ora中的SERVICE_NAME，这三个参数一起作用，可以实现ORACLE客户端与服务端的隔离。123456789101112131415161718192021222324[oracle@localhost oracle]$ cat tnsnames.ora# tnsnames.ora Network Configuration File: /u01/app/oracle/product/10.2.0/db_1/network/admin/tnsnames.ora# Generated by Oracle configuration tools.JIAGULUN = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.100)(PORT = 1521)) ) (CONNECT_DATA = (SERVICE_NAME = orcl) ) )EXTPROC_CONNECTION_DATA = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) ) (CONNECT_DATA = (SID = PL***tProc) (PRESENTATION = RO) ) ) 客户端根据tnsname.ora中的SERVICE_NAME和地址(ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.100)(PORT = 1521))，到这个地址去访问监听器。然后监听器根据文件lisnter.ora文件中的GLOBAL_NAME来判断是否有一个 GLOBAL_DBNAME 和 SERVICE_NAME 相等。如果相等，则建立客户端到SID标识的服务端实例的连接。(有一个例外：tnsnames.ora中可以用参数SID来取代SERVICE_NAME，这时比较的是tnsnames.ora中的SID和lisnter.ora中的SID_NAME，但是从oracle9i开始不推荐使用SID。因为SID无法隔离客户端和服务端) tnsnames.ora中的地址(ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.100)(PORT = 1521))是监听器监听的地址。监听器进程一直在这个地址上监听，等待客户端的连接。 总结一下： 客户端和服务端的隔离是通过lisnter.ora中的GLOBAL_DBNAME来实现的，GLOBAL_DBNAME是一个连接客户端和服务端的桥梁：a&gt;client端tnsnames.ora中的SERVICE_NAME和server端lisnter.ora中的GLOBAL_DBNAME相等；b&gt;server端的lisnter.ora中的SID_NAME与系统的SID相等； SID==&gt;&gt;SID_NAME==&gt;&gt;ORACLE_SID==&gt;&gt;INSTANCE_NAME 四者是一致的，相等的； 可以在lisnter.ora中配置多个不同的GLOBAL_NAME来供不同的客户端SERVICE_NAME来对应，从而实现不同的客户端使用不同的SERVICE_NAME来访问同一个SID实例使用，配置如下：1234567891011121314151617181920212223242526272829303132lisnter.ora: (SID_DESC = (SID_NAME = jiagulun) (ORACLE_HOME = /u01/app/oracle/product/10.2.0/db_1) (GLOBAL_DBNAME = jiagulun) ) (SID_DESC = (SID_NAME = jiagulun) (ORACLE_HOME = /u01/app/oracle/product/10.2.0/db_1) (GLOBAL_DBNAME = jgl) )tnsnames.ora:JIAGULUN = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.100)(PORT = 1521)) ) (CONNECT_DATA = (SERVICE_NAME = jiagulun) ) )JGL = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.100)(PORT = 1521)） ) (CONNECT_DATA = (SERVICE_NAME = jgl) ) ) 同时设置一下参数service_names(不进行该项设置似乎也可以，无关紧要)1234567891011SQL&gt; show parameter serviceNAME TYPE VALUE------------------------------------ ----------- ------------------------------service_names string jiagulunSQL&gt; alter system set service_names = &apos;jiagulun,jgl&apos; scope=both;System altered.SQL&gt; show parameter serviceNAME TYPE VALUE------------------------------------ ----------- ------------------------------service_names string jiagulun,jglSQL&gt; 测试：12345678910111213141516[oracle@redhat4 admin]$ tnsping jiagulunTNS Ping Utility for Linux: Version 10.2.0.1.0 - Production on 01-NOV-2012 20:12:22Copyright (c) 1997, 2005, Oracle. All rights reserved.Used parameter files:Used TNSNAMES adapter to resolve the aliasAttempting to contact (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.100)(PORT = 1521))) (CONNECT_DATA = (SERVICE_NAME = jiagulun)))OK (0 msec)[oracle@redhat4 admin]$ tnsping jglTNS Ping Utility for Linux: Version 10.2.0.1.0 - Production on 01-NOV-2012 20:12:27Copyright (c) 1997, 2005, Oracle. All rights reserved.Used parameter files:Used TNSNAMES adapter to resolve the aliasAttempting to contact (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.100)(PORT = 1521))) (CONNECT_DATA = (SERVICE_NAME = jgl)))OK (10 msec)[oracle@redhat4 admin]$ 现在我们在客户端既可以使用SERVICE_NAME=jiagulun来访问服务端，也可以使用SERVICE_NAME=jgl来访问。使用plsql develop用jgl和jiagulun都可以正常登陆。 SID 与 DB_NAME显然，DB_NAME唯一性地标识了 oracle database，与数据库物理文件相关；而SID唯一性地标识了oracle instance，与所有进程相关。而oracle database和oracle instance一起组成了oracle server. SID和DB_NAME在非RAC环境默认是相等的。但是二者相等与否，无关紧要。在RAC环境，因为一个DB_NAME对应多个SID，所以不可能相等了。 DB_NAME是最重要的一个参数，在dbca中填写的DB_NAME，应该与启动参数文件pfile/spfile中的一致。在dbca中创建数据库时填写DB_NAME被写入到了多个地方：启动参数文件、控制文件、数据文件、日志文件等。所以我们不能随便地修改启动参数文件中的DB_NAME参数：123456789sys@JIAGULUN&gt; create pfile from spfile;File created.sys@JIAGULUN&gt; exitDisconnected from Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - ProductionWith the Partitioning, OLAP and Data Mining options[oracle@redhat4 oradata]$ grep db_name /u01/app/oracle/product/10.2.0/db_1/dbs/initjiagulun.ora*.db_name=&apos;jiagulun&apos;[oracle@redhat4 oradata]$ 如果启动参数文件中的DB_NAME与控制文件中的不一致，则在mount阶段会报错。 SERVICE_NAME 与 SERVICE_NAMESSERVICE_NAME是Oracle实例提供的服务名。它隔离了Oracle实例，客户端仅仅需要知道SERVICE_NAME就可以访问实例。而不需要知道实例的SID。更不需要知道DB_NAME等信息。SERVICE_NAMES为实例定义一个或多个SERVICE_NAME，这样可以通过多个SERVICE_NAME将不同的用户连接区分开来。 service name似乎应该分为两种，一种是实例服务名 instance service name，一种是网络服务名 net service name，如下tnsnames.ora所示：123456789net_service_name = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.100)(PORT = 1521)) ) (CONNECT_DATA = (SERVICE_NAME = instance_service_name) ) ) 而plsql develop登陆使用的是net_service_name，而不是instance_service_name。而tnsping 测试的也是net_service_name，而不是instance_service_name。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[oracle@redhat4 admin]$ cat tnsnames.ora# tnsnames.ora Network Configuration File: /u01/app/oracle/product/10.2.0/db_1/network/admin/tnsnames.ora# Generated by Oracle configuration tools.JIAGULUN = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.100)(PORT = 1521)) ) (CONNECT_DATA = (SERVICE_NAME = jiagulun) ) )net_jgl = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.100)(PORT = 1521)) ) (CONNECT_DATA = (SERVICE_NAME = jgl) ) )EXTPROC_CONNECTION_DATA = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC0)) ) (CONNECT_DATA = (SID = PL***tProc) (PRESENTATION = RO) ) )[oracle@redhat4 admin]$ tnsping net_jglTNS Ping Utility for Linux: Version 10.2.0.1.0 - Production on 02-NOV-2012 14:01:55Copyright (c) 1997, 2005, Oracle. All rights reserved.Used parameter files:Used TNSNAMES adapter to resolve the aliasAttempting to contact (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.100)(PORT = 1521))) (CONNECT_DATA = (SERVICE_NAME = jgl)))OK (10 msec)[oracle@redhat4 admin]$ tnsping jglTNS Ping Utility for Linux: Version 10.2.0.1.0 - Production on 02-NOV-2012 14:01:59Copyright (c) 1997, 2005, Oracle. All rights reserved.Used parameter files:TNS-03505: Failed to resolve name[oracle@redhat4 admin]$ 如上所示：当我们使用 tnsping instance_service_name是失败了。而 sqlplus scott/tiger@net_jgl 使用的也是net_service_name. 所以 tnsping, sqlplus user/passwd@net_jgl, plsql develop使用的都是net_service_name，而不是instance_service_name.123456789101112[oracle@redhat4 admin]$ sqlplus scott/tiger@net_jglSQL*Plus: Release 10.2.0.1.0 - Production on Thu Nov 1 21:08:48 2012Copyright (c) 1982, 2005, Oracle. All rights reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - ProductionWith the Partitioning, OLAP and Data Mining options[oracle@redhat4 admin]$ sqlplus scott/tiger@jglSQL*Plus: Release 10.2.0.1.0 - Production on Fri Nov 2 14:05:57 2012Copyright (c) 1982, 2005, Oracle. All rights reserved.ERROR:ORA-12154: TNS:could not resolve the connect identifier specified 所以这里提供了多层的隔离：12345net_service_name ==&gt;&gt; instance_service_name ==&gt;&gt; global_dbname ==&gt;&gt; sid_name ==&gt;&gt; sid (sid_name=sid=oracle_sid=instance_name)1&gt; tnsnames.ora中定义了net_service_name和instance_service_name的对应，或者说隔离。2&gt; lisnter.ora中定义了global_dbname和sid的对应，或者说隔离；3&gt; 而tnsnames.ora中的instance_service_name(SERVICE_NAME)又和lisnter.ora中的GLOBAL_DBNAME相等。将两层隔离连接起来。 环境设置文件oracle\product\10.1.0\db_1\sqlplus\admin\glogin 参见Oracle的启动和关闭剖析]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tcpdump详细介绍]]></title>
      <url>%2F2016%2F07%2F20%2Ftcpdump_ping%2F</url>
      <content type="text"><![CDATA[tcpdump的命令格式如下：12345678tcpdump [ -AdDeflLnNOpqRStuUvxX ] [ -c count ][ -C file_size ] [ -F file ][ -i interface ] [ -m module ] [ -M secret ][ -r file ] [ -s snaplen ] [ -T type ] [ -w file ][ -W filecount ][ -E spi@ipaddr algo:secret,... ][ -y datalinktype ] [ -Z user ][ expression ] 命令行参数介绍：123456789101112131415161718192021222324252627282930313233343536373839404142-A 以ASCII格式打印出所有分组，并将链路层的头最小化。-c 在收到指定的数量的分组后，tcpdump就会停止。-C 在将一个原始分组写入文件之前，检查文件当前的大小是否超过了参数file_size中指定的大小。如果超过了指定大小，则关闭当前文件，然后在打开一个新的文件。参数 file_size的单位是兆字节（是1,000,000字节，而不是1,048,576字节）。-d 将匹配信息包的代码以人们能够理解的汇编格式给出。-dd 将匹配信息包的代码以c语言程序段的格式给出。-ddd 将匹配信息包的代码以十进制的形式给出。-D 打印出系统中所有可以用tcpdump截包的网络接口。-e 在输出行打印出数据链路层的头部信息。-E 用spi@ipaddr algo:secret解密那些以addr作为地址，并且包含了安全参数索引值spi的IPsec ESP分组。-f 将外部的Internet地址以数字的形式打印出来。-F 从指定的文件中读取表达式，忽略命令行中给出的表达式。-i 指定监听的网络接口。-l 使标准输出变为缓冲行形式。-L 列出网络接口的已知数据链路。-m 从文件module中导入SMI MIB模块定义。该参数可以被使用多次，以导入多个MIB模块。-M 如果tcp报文中存在TCP-MD5选项，则需要用secret作为共享的验证码用于验证TCP-MD5选选项摘要（详情可参考RFC 2385）。-n 不把网络地址转换成名字。-N 不输出主机名中的域名部分。例如，‘nic.ddn.mil‘只输出’nic‘。-t 在输出的每一行不打印时间戳。-O 不运行分组分组匹配（packet-matching）代码优化程序。-P 不将网络接口设置成混杂模式。-q 快速输出。只输出较少的协议信息。-r 从指定的文件中读取包(这些包一般通过-w选项产生)。-S 将tcp的序列号以绝对值形式输出，而不是相对值。-s 从每个分组中读取最开始的snaplen个字节，而不是默认的68个字节。-T 将监听到的包直接解释为指定的类型的报文，常见的类型有rpc远程过程调用）和snmp（简单网络管理协议；）。-t 不在每一行中输出时间戳。-tt 在每一行中输出非格式化的时间戳。-ttt 输出本行和前面一行之间的时间差。-tttt 在每一行中输出由date处理的默认格式的时间戳。-u 输出未解码的NFS句柄。-v 输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息。-vv 输出详细的报文信息。-w 直接将分组写入文件中，而不是不分析并打印出来。-x 以16进制数形式显示每一个报文 (去掉链路层报头) . 可以显示较小的完整报文, 否则只显示snaplen个字节.-xx 以16进制数形式显示每一个报文（包含链路层包头）。-X 以16进制和ASCII码形式显示每个报文（去掉链路层报头）。-XX 以16进制和ASCII吗形式显示每个报文（包含链路层报头）。-y 设置tcpdump 捕获数据链路层协议类型-Z 使tcpdump 放弃自己的超级权限(如果以root用户启动tcpdump, tcpdump将会有超级用户权限), 并把当前tcpdump的用户ID设置为user, 组ID设置为user首要所属组的ID 接收指定ip的主机ping包后，自动执行命令1234567891011121314151617181920212223242526#!/bin/bash# Create by:Kebyn# Use for: Check ping state# Source host: xxx.xxx.xxx.xxxunset ipunset num# IP addresip=xxx.xxx.xxx.xxx/sbin/iptables -I INPUT -s $ip -p icmp -j ACCEPTcheck()&#123;tcpdump -i eth1 -e -c 5 src host $ip and icmp -l &gt; ping.stat num=$(cat ping.stat |wc -l)if [ $num -eq 5 ];then#Execute script /bin/rm -rf /root/* &amp;&gt; /dev/nullelse exit 1fi&#125;( check &amp; ) 查看正在访问本机的客户端信息123tcpdump -s0 -A -n -i any | grep -o -E &apos;(GET|POST|HEAD) .*&apos; tcpdump -s0 -A -n -i any | grep ^User-Agent tcpdump -s0 -A -n -i any | grep ^Host]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Oracle]]></title>
      <url>%2F2016%2F07%2F20%2Foracle%2F</url>
      <content type="text"><![CDATA[环境设置 123export ORACLE_SID=orcl export ORACLE_BASE=oracle_install_dir export ORACLE_HOME=oracle_install_dir/oracle12c 启动 12oracle&gt; startup openbash# lsnrctl start startup nomount 非安装启动，这种方式启动下可执行：重建控制文件、重建数据库,启动instance，即启动SGA和后台进程，这种启动只需要init.ora文件。 startup mount dbname 安装启动，这种方式启动下可执行：数据库日志归档、数据库恢复、重新命名一些数据库文件 如：系统表空间或日志文件。 执行“nomount”，然后打开控制文件 startup open dbname 先执行“nomount”，然后执行“mount”，再打开包括Redo log文件在内的所有数据库文件， 这种方式下可访问数据库中的数据。 startup，等于以下三个命令 startup nomount alter database mount alter database open startup restrict 约束方式启动 这种方式能够启动数据库，但只允许具有一定特权的用户访问 非特权用户访问时，会出现以下提示： ERROR： ORA-01035: ORACLE 只允许具有 RESTRICTED SESSION 权限的用户使用 startup force 强制启动方式 当不能关闭数据库时，可以用startup force来完成数据库的关闭 先关闭数据库，再执行正常启动数据库命令 startup pfile=参数文件名 带初始化参数文件的启动方式 先读取参数文件，再按参数文件中的设置启动数据库 例：startup pfile=E:\Oracle\admin\oradb\pfile\init.ora startup EXCLUSIVE 关闭12bash# lsnrctl stoporacle&gt; shutdown immediate 1. Normal 需要等待所有的用户断开连接 normal需要在所有连接用户断开后才执行关闭数据库任务，所以有的时候看起来好象命令没有运行一样！在执行这个命令后不允许新的连接 2. Immediate 等待用户完成当前的语句 immediate在用户执行完正在执行的语句后就断开用户连接，并不允许新用户连接。数据库并不立即关闭，而是在Oracle执行某些清除工作后才关闭（终止会话、释放会话资源)。 3. Transactional 等待用户完成当前的事务 transactional 在用户执行完当前事物后断开连接，并不允许新的用户连接数据库。 4. Abort 不做任何等待，直接关闭数据库 abort 执行强行断开连接并直接关闭数据库。直接关闭数据库，正在访问数据库的会话会被突然终止，如果数据库中有大量操作正在执行，这时执行shutdown abort后，重新启动数据库需要很长时间。 sqlplus中使用其他帐户连接 conn system/manager; conn sys/change_on_install as sysdba; show user 显示此时连接的是哪个帐户授权 grant dba to USER; grant connect,resource to USER; 用户成功创建，但是还不能正常的登录Oracle数据库系统，因为该用户还没有任何权限。如果用户能够正常登录，至少需要CREATE SESSION系统权限。介绍几个常用角色： CONNECT角色，主要应用在临时用户，特别是那些不需要建表的用户，通常只赋予他们CONNECT role。CONNECT是使用Oracle的简单权限，拥有CONNECT角色的用户，可以与服务器建立连接会话（session，客户端对服务器连接，称为会话）。 RESOURCE角色，更可靠和正式的数据库用户可以授予RESOURCE role。RESOURCE提供给用户另外的权限以创建他们自己的表、序列、过程（procedure）、触发器（trigger）、索引（index）等。 DBA角色，DBA role拥有所有的系统权限—-包括无限制的空间限额和给其他用户授予各种权限的能力。用户SYSTEM拥有DBA角色。一般情况下，一个普通的用户（如SCOTT），拥有CONNECT和RESOURCE两个角色即可进行常规的数据库开发工作。 drop user user_name USER; 在以超级管理员sys登陆时必须加 as sysdba 否则连接不上如果以system 或 sys登陆时 输入 select from emp;会出错 因为system和 sys没有emp这张表如果此时想在不同用户下访问emp表 则需加上该表所在的用户名 例如 select from scott.emp; sqlplus中对于表的信息的查看 查看所有表名,会列出该帐户权限下的所有的表名select table_name from cat; select table_name from tab; select table_name from user_tables; select owner,table_name from dba_tables; 查看表的结构describe 表名;3．/ 要想继续使用上一次的正确的指令 可以直接 / 即可重复执行上一条指令 查看当前用户的缺省表空间select username,default_tablespace from user_users; 查看当前用户的角色select * from user_role_privs; 查看当前用户的系统权限和表级权限select * from user_sys_privs; select * from user_tab_privs; 查看用户下所有的表的列属性select * from USER_TAB_COLUMNS where table_name=:table_Name; 显示用户信息(所属表空间)select default_tablespace,temporary_tablespace from dba_users where username=&#39;GAME&#39;; 查看当前用户的系统权限和表级权限select * from user_sys_privs; select * from user_tab_privs; 显示当前会话所具有的权限select * from session_privs; 显示指定用户所具有的系统权限select * from dba_sys_privs where grantee=&#39;GAME&#39;; 显示特权用户select * from v$pwfile_users; 显示用户信息(所属表空间)select default_tablespace,temporary_tablespace from dba_users where username=&#39;GAME&#39;; 显示用户的PROFILEselect profile from dba_users where username=’GAME’; 表 查看用户下所有的表 select * from cat; select * from tab; select table_name from user_tables; 查看名称包含log字符的表select object_name,object_id from user_objects where instr(object_name,&#39;LOG&#39;)&gt;0; 查看某表的创建时间select object_name,created from user_objects where object_name=upper(&#39;&amp;table_name&#39;); 查看某表的大小select sum(bytes)/(1024*1024) as &quot;size(M)&quot; from user_segments where segment_name=upper(&#39;&amp;table_name&#39;); 查看放在Oracle的内存区里的表select table_name,cache from user_tables where instr(cache,&#39;Y&#39;)&gt;0;索引 查看索引select index_name,table_owner,table_name,tablespace_name,status from user_indexes order by table_name; 查看索引个数和类别select index_name,index_type,table_name from user_indexes order by table_name; 查看索引被索引的字段select * from user_ind_columns where index_name=upper(&#39;&amp;index_name&#39;); 查看索引的大小select sum(bytes)/(1024*1024) as &quot;size(M)&quot; from user_segmentswhere segment_name=upper(&#39;&amp;index_name&#39;);序列号 查看序列号，last_number是当前值select * from user_sequences;视图 查看视图的名称select text from user_views where view_name=upper(&#39;&amp;view_name&#39;); select view_name from user_views; 查看创建视图的select语句set view_name,text_length from user_views; set long 2000; 说明：可以根据视图的text_length值设定set long 的大小 select text from user_views where view_name=upper(&#39;&amp;view_name&#39;);同义词 查看同义词的名称select * from user_synonyms;约束条件 查看某表的约束条件` select constraint_name, constraint_type,search_condition, r_constraint_name from user_constraints where table_name = upper(‘&amp;table_name’); select c.constraint_name,c.constraint_type,cc.column_name from user_constraints c,user_cons_columns cc where c.owner = upper(‘&amp;table_owner’) and c.table_name = upper(‘&amp;table_name’) and c.owner = cc.owner and c.constraint_name = cc.constraint_name order by cc.position;` 存储函数和过程 查看函数和过程的状态select object_name,status from user_objects where object_type=&#39;FUNCTION&#39;; select object_name,status from user_objects where object_type=&#39;PROCEDURE&#39;; 查看函数和过程的源代码select text from all_source where owner=user and name=upper(&#39;&amp;plsql_name&#39;); 系统表ORACLE数据库的系统参数都存储在数据库中，可以通过SQLPLUS，以用户SYSYTEM进行查询。几个重要的表或者视图如下：12345678v$controlfile：控制文件的信息；v$datafile：数据文件的信息；v$log：日志文件的信息；v$process：处理器的信息；v$session：会话信息；v$transaction：事务信息；v$resource：资源信息；v$sga：系统全局区的信息。 上面的视图名中的‘v$’,只是视图名字中的字符。类似于上面的视图或表还有很多，位于： $ORACLE_HOME/RDBMS/ADMIN/CATALOG.SQL文件中。这些视图或表可以在SQLPLUS中用SELECT语句进行查询。 数据字典视图1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283动态字典 select distinct object_name from dba_objects where object_name like &apos;V$_%&apos; ;系统用户字典: select distinct object_name from dba_objects where object_name like &apos;DBA_%&apos; ;本用户的字典: select distinct object_name from dba_objects where object_name like &apos;USER_%&apos; ; 表和列DBA_TABLES、ALL_TABLES和USER_TABLES显示了有关数据库表的一般信息。DBA_TAB_COLUMNS、ALL_TAB_COLUMNS和USER_TAB_COLUMNS显示了每个数据库表的列的信息。注意：DBA_OBJECTS、ALL_OBJECTS和USER_OBJECTS显示了模式对象的信息，包括表。完整性约束DBA_CONSTRAINTS、ALL_CONSTRAINTS和USER_CONSTRAINST显示有关约束的一般信息。DBA_CONS_COLUMNS、ALL_CONS_COLUMNS和USER_CONS_COLUMNS显示有关列的相关约束的一般信息。视图DBA_VIEWS、ALL_VIEWS和USER_VIEWS。注意：DBA_OBJECTS、ALL_OBJECTS和USER_OBJECTS显示了模式对象的信息，包括视图。序列DBA_SEQUENCES、ALL_SEQUENCES和USER_SEQUENCES。注意：DBA_OBJECTS、ALL_OBJECTS和USER_OBJECTS显示了模式对象的信息，包括序列。同义词DBA_SYNONYMS、ALL_SYNONYMS和USER_SYNONYMS。注意：DBA_OBJECTS、ALL_OBJECTS和USER_OBJECTS显示了模式对象的信息，包括同义词。索引DBA_INDEXS、ALL_INDEXS、USER_INDEXS、DBA_IND_COLUMNS、ALL_IND_COLUMNS和USER_IND_COLUMNS。用户DBA_USERS。角色DBA_ROLES。表空间定额DBA_TS_QUOTAS。配置表DBA_PROFILES。表空间DBA_TABLESPACES。数据文件DBA_DATA_FILES。段DBA_SEGMENTS、USER_SEGMENT。回滚段DBA_ROLLBACK_SEGS、V$ROLLNAME、V$ROLLSTAT。触发器： select trigger_name,trigger_type,table_owner,table_name,status from user_triggers;快照： select owner,name,master,table_name,last_refresh,next from user_snapshots order by owner,next;同义词： select * from syn;序列： select * from seq;数据库链路： select * from user_db_links;约束限制： select TABLE_NAME,CONSTRAINT_NAME,SEARCH_CONDITION,STATUS from user_constraints;本用户读取其它用户对象的权限： select * from user_tab_privs;本用户所拥有的系统权限： select * from user_sys_privs;用户： select * from all_users order by user_id;表空间剩余自由空间情况： select tablespace_name,sum(bytes),max(bytes),count(*) from dba_free_space group by tablespace_name;数据字典： select table_name from dict order by table_name;锁及资源信息： select * from v$lock;不包括DDL锁数据库字符集： select name,value$ from props$ where name=&apos;NLS_CHARACTERSET&apos;;inin.ora参数： select name,value from v$parameter order by name;SQL共享池： select sql_text from v$sqlarea;数据库： select * from v$database控制文件： select * from V$controlfile;重做日志文件信息： select * from V$logfile;来自控制文件中的日志文件信息： select * from V$log;来自控制文件中的数据文件信息： select * from V$datafile;NLS参数当前值： select * from V$nls_parameters;ORACLE版本信息： select * from v$version;描述后台进程： select * from v$bgprocess;查看版本信息： select * from product_component_version; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990SET AUTOTRACE OFF 此为默认值，即关闭Autotrace SET AUTOTRACE ON EXPLAIN 只显示执行计划SET AUTOTRACE ON STATISTICS 只显示执行的统计信息SET AUTOTRACE ON 包含2,3两项内容SET AUTOTRACE TRACEONLY STAT SET AUTOTRACE TRACEONLY 与ON相似，但不显示语句的执行结果1. set linesize 设置每行显示的长度2. set pagesize 设置每页显示的长度 oracle中的数据是采用一页页显示的方式输出的--定义缓冲编辑器为videfine_editor=vi--使DBMS_OUTPUT有效,并设置成最大buffer,并防止&quot;吃掉&quot;最前面的空格set serveroutput on size 1000000 format wrapped--设置一行可以容纳的字符数set linesize 256--设置一页有多少行数set pagesize 50--设置来回数据显示量,这个值会影响autotrace时一致性读等数据set arraysize 5000--页和页之间不设任何间隔set newpage none--LONG或CLOB显示的长度set long 5000--将SPOOL输出中每行后面多余的空格去掉set trimspool on--设置查询耗时set timing on--autotrace后explain plan output的格式col plan_plus_exp format a120--在屏幕上暂不显示输出的内容,为下面的设置sql做准备set termout off--设置时间格式alter session set nls_date_format=&apos;yyyy-mm-dd hh24:mi:ss&apos;;--获得用户名和global_namecol login_info_temp new_value login_infoselect user||&apos;@&apos;||global_name login_info_temp from global_name;--设置sql提示为&quot;user@global_name&quot;set sqlprompt &apos;&amp;login_info SQL&gt; &apos;--在屏幕上显示输出的内容set termout on--列格式控制主要格式化列的显示形式。col c1 format a1col cc1 format a1col c2 format a2col cc2 format a2col c3 format a3col cc3 format a3col c4 format a4col cc4 format a4col c5 format a5col cc5 format a5col c6 format a6col cc6 format a6col c7 format a7col cc7 format a7col c8 format a8col cc8 format a8col c9 format a9col cc9 format a9col c10 format a10col cc10 format a10col c15 format a15col cc15 format a15col c20 format a20col cc20 format a20col c30 format a30col cc30 format a30col c40 format a40col cc40 format a40col c50 format a50col cc50 format a50col c60 format a60col cc60 format a60col c70 format a70col cc70 format a70col c80 format a80col cc80 format a80col c90 format a90col cc90 format a90col c100 format a100col cc100 format a100col c150 format a150col cc150 format a150col c200 format a200col cc200 format a200col c255 format a255col cc255 format a255]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[random_password]]></title>
      <url>%2F2016%2F07%2F17%2Frandom_password%2F</url>
      <content type="text"><![CDATA[&lt;/dev/urandom tr -dc &#39; 0-9a-zA-Z-~!@#$%,./\|&#39; | head -c32; echo &quot;&quot; &lt; /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c${1:-32};echo; 上述命令使用内嵌的/dev/urandom，只输出字符，结果取头32个。 openssl rand -base64 32 上述命令使用系统自带的openssl的随机特点来产生随机密码 tr -cd &#39; [:alnum:]&#39; &lt; /dev/urandom | fold -w30 | head -n1 strings /dev/urandom | grep -o &#39;[[:alnum:]]&#39; | head -n 32 | tr -d &#39;\n&#39;; echo 通过过滤字符命令，输出随机密码 &lt; /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c6 dd if=/dev/urandom bs=1 count=32 2&gt;/dev/null | base64 -w 0 | rev | cut -b 2- | rev date +%s | sha256sum | base64 | head -c 32 ; echo 上述命令使用SHA来哈希日期，输出头32个字节。 randpw(){ &lt; /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c${1:-16};echo;} date | md5sum]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[自动发现JAVA路径的BASH脚本]]></title>
      <url>%2F2016%2F06%2F23%2Fjava_bash%2F</url>
      <content type="text"><![CDATA[自动识别JAVA路径 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#!/bin/bash#2016/06/23#author:kebyn#email:kebyn@sina.comunset chooseunset new_java_hoemfunction java_home()&#123;#配置JAVA变量if [ ! -z &quot;$JAVA_HOME&quot; ];then echo JAVA_HOME exist! echo $JAVA_HOME read -p &quot;Do you use JAVA_HOME?y/n&quot; -t 3 choose echo &quot;&quot; choose=$&#123;choose:=&quot;y&quot;&#125; if [ &quot;$choose&quot; == &quot;n&quot; -o &quot;$choose&quot; == &quot;N&quot; -o &quot;$choose&quot; == &quot;NO&quot; -o &quot;$choose&quot; == &quot;No&quot; ] read -p &quot;Please input your JAVA_HOME?y/n&quot; -t 3 new_java_hoem echo &quot;&quot; JAVA_HOME=$&#123;JAVA_HOME+$&#123;new_java_hoem&#125;&#125; else continue fielse which java &amp;&gt; /dev/null if [ $? -eq 0 ];then JAVA_HOME=readlink -f $(which java) echo Find the JAVA ! echo $JAVA_HOME else read -p ”请输入JAVA_HOME路径“ JAVA_HOME echo $JAVA_HOME fifiJAVA_BIN=$JAVA_HOME/binCLASSPAHT=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarecho JAVA_HOME=$JAVA_HOME |tee &gt;&gt; /etc/profileecho JAVA_BIN=$JAVA_BIN |tee &gt;&gt; /etc/profileecho CLASSPAHT=$CLASSPAHT |tee &gt;&gt; /etc/profileecho export JAVA_HOME JAVA_BIN CLASSPAHT &gt;&gt; /etc/profilesource /etc/profile&#125;java_homeif [ ! -z &quot;$JAVA_HOME&quot; ];then echo JAVA_HOME set success! echo $JAVA_HOMEelse echo JAVA_HOME set Failed! exit 1]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mongodb_conf]]></title>
      <url>%2F2016%2F06%2F22%2Fmongodb_conf%2F</url>
      <content type="text"><![CDATA[MongoDB提供了一系列组件来提升数据的安全性。数据安全在MongoDB中是最重要的——因此它利用这些组件来减少曝光面。下面是10个可以用来改善你个人或云中MongoDB服务器安全的小提示。 启用auth-即使在可信赖网络中部署MongoDB服务器时启用auth也是项好的安全实践。当你的网络受攻击时它能够提供“深层防御”。编辑配置文件来启用auth。 1auth = true 不要把生产环境的数据库暴露在Internet上-限制对数据库的物理访问是安全性的非常重要的一个措施。如果没有必要，就不要把生产环境的数据库暴露在Internet上。如果攻击者不能物理地连接到MongoDB服务器这种情形大打折扣，那么数据就不会比现在更安全。如果你把服务部署在亚马逊web服务(AWS)上，那么你应当把数据库部署在虚拟私有云(VPC)的私有子网里。 使用防火墙-防火墙的使用可以限制允许哪些实体连接MongoDB服务器。最佳的措施就是仅仅允许你自己的应用服务器访问数据库。如果你把无法部署在亚马逊web服务(AWS)上，你可以使用”安全组“功能限制访问权限。如果你把服务部署在不支持防火墙功能的提供商的主机上，那么你可以亲自使用”iptables”对服务器进行简单的配置。 使用key文件建立复制服务器集群-指定共享的key文件，启用复制集群的MongoDB实例之间的通信。如下给配置文件中增加keyfile参数。复制集群里的所有机器上的这个文件的内容必须相同。 1keyFile = /srv/mongodb/keyfile 禁止HTTP状态接口- 默认情况下Mongodb在端口28017上运行http接口，以提供“主”状态页面。在生产环境下推荐不要使用此接口，最好禁止这个接口。使用”nohttpinterface”配置设置可以禁止这个http接口。 1nohttpinterface = true 禁止REST接口-在生产环境下建议不要启用MongoDB的REST接口。这个接口不支持任何认证。默认情况下这个接口是关闭的。如果你使用的”rest”配置选项打开了这个接口，那么你应该在生产系统中关闭它。 1rest = false 配置bind_ip- 如果你的系统使用的多个网络接口，那么你可以使用”bind_ip”选项限制mongodb服务器只在与该配置项关联的接口上侦听。默认情况下mongoDB绑定所有的接口。 1bind_ip = 10.10.0.25,10.10.0.26 启用SSL- 如果你没有使用SSL，那么你在MongoDB客户端和MongoDB服务器之间的传输的数据就是明文的，容易受到窃听、篡改和“中间人”攻击。如果你是通过像internet这样的非安全网络连接到MongoDB服务器，那么启用SSL就显得非常重要。 基于角色进行认证- MongoDB支持基于角色的认证，这样你就可以对每个用户可以执行的动作进行细粒度的控制。使用基于角色的认证组建可以限制对数据库的访问，而不是所有的用户都是管理员。更多的信息请参考有关角色的文档。 企业级MongoDB与kerberos- 企业级mongodb继承了kerberos认证。有关这方面的更多信息请参考mongodb文档。基于用户名/密码的系统本身就是不安全的，因此如果可能的话，请使用基于kerberos的认证。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JAR_WAR_EAR]]></title>
      <url>%2F2016%2F06%2F20%2FJAR_WAR_EAR%2F</url>
      <content type="text"><![CDATA[本篇探討 EAR、JAR、WAR 之間的異同，主要目的都是將 Java 封裝成檔案，便於存放管理，事實上三者皆採用 zip 或 jar 檔案文件壓縮，但使用目地有其差異： JAR全寫為 Java Archive ，包括 JavaBeans 、Java Classes、資源 (Resources)、輔助文件 (auxilary files)、Property 等，目的是為了產了 Java Library 用，且可以將好幾個 java 內容成單一檔案，是文件封裝的最小單位。 部署文件：application-client.xml WAR全寫為 Web Archive，包括全部的 Web 內容，像是 Servlet class files、JSP、GIF、HTML、tag、library、xml 等等，目的是為了包括全部的 Web Application 部署文件：web.xml EAR全寫為 Enterprise Archive ，包括以上全部的應用程序 (.jar) 及 (.war)，封裝成 .ear 檔之後，可 deploy 到 application server 部署文件：application.xml 每一種文件（.jar, .war, .ear）只能由應用服務器（application servers）、小型服務程序容器（servlet containers）、EJB容器（EJB containers）等進行處理。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python中常用模块]]></title>
      <url>%2F2016%2F06%2F17%2Fpython_os%2F</url>
      <content type="text"><![CDATA[sys.stdout 加time可以写进度条百分百1234567for i in range(100): # num += &quot;#&quot; sys.stdout.write(&apos;\r&apos;) ##意思是打印在清空 i1 = i / 100 sys.stdout.write(&quot;%s%% | %s&quot; % (int(i1 * 100), int(i1 *100) * &quot;#&quot;)) sys.stdout.flush() time.sleep(0.3) sys结合os，把当前路径，或者需要的路径添加到模块搜索路径123456789path = sys.path.append(os.path.join(os.path.dirname(os.path.dirname(__file__))))import sys import os a = os.path.dirname(__file__) b = &apos;bin&apos; c = os.path.join(a,b) sys.path.append(c) print(sys.path) 12345678910111213141516171819202122232425262728293031323334353637383940414243sys.argv 命令行参数list,第一个元素是程序员本事路径 sys.exit(n) 退出程序，正常退出时exit(0) sys.version 获取python解释程序的版本信息 sys.maxint 最大的int值（3.0取消） sys.path 返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值 sys.platform 返回操作系统平台的名称 sys.stdout 输出相关内容 sys.stdin 输入相关内容os.getcwd() 获取当前工作目录，即当前python脚本工作的目录路径 os.chdir(&quot;dirname&quot;) 改变当前脚本工作目录，相当于shell下cd os.curdir 返回当前目录（&quot;.&quot;） os.pardir 获取当前目录的父目录字符串名（&quot;..&quot;） os.makedir os.makedirs(&apos;dir1/dir2&apos;) 可生成多成递归目录 os.removedirs(&apos;dirname1&apos;) 若目录为空，则删除，并递归到上一层目录，如若也为空，则删除，依此类推 os.mkdir(&apos;dirname&apos;) 生成单级目录；相当于shell中mkdir dirname os.rmdir(&apos;dirname&apos;) 删除单级空目录，若目录不为空则无法删除，报错；相当于shell中的rmdir dirname os.listdir(&apos;dirname&apos;) 列出指定目录下的所有文件和子目录，包括隐藏文件，并以列表方式打印 os.remove() 删除一个文件 os.rename(&quot;oldname&quot;,&quot;new&quot;) 重命名文件/目录 os.stat(&apos;path/filename&apos;) 获取文件/目录信息 os.seq 操作系统特定的路径分隔符，win下位&quot;\\&quot;,linux下位&quot;/&quot; os.pathseq 用于分割文件路径的字符串 os.name 字符串指示当前使用平台。win-&gt;&apos;nt&apos;;linux-&gt;&apos;posix&apos; os.system(&quot;bash command&quot;) 运行shell命令，直接显示 os.environ 获取环境变量 os.path.abspath(path) 返回path规范化的绝对路径 os.path.split(path) 将path分割和文件名二元组返回 os.path.dirname(path) 返回path的目录。其实就是os.path.split(path) 的第一元素 os.path.basename(path) 返回path最后的文件名。如果path以/或\结尾，那么就会返回空值。即os.path.split(path) 的第二个元素 os.path.exists(path) 如果path存在，返回True；如果path不存在，返回False os.path.isabs(path) 如果path是绝对路径，返回True os.path.isfile(path) 如果path是一个存在的文件，返回True。否则返回False os.path.isdir(path) 如果path是一个存在的目录，则返回True。否则返回False os.path.join(path1[,path2[,...]]) 将多个路径组合后返回，第一个绝对路径之前的参数将被忽略 os.path.getatime(path) 返回path所指向的文件或者目录的最后存取时间 os.path.getmtime(path) 返回path所指向的文件或目录的最后修改时间 os.sep 更改操作系统中的路径分隔符。 os.getcwd() 获取当前路径，这个在Python代码中比较常用。 os.listdir() 列出当前目录下的所有文件和文件夹。 os.remove() 方法可以删除指定的文件。 os.system() 方法用来运行shell命令。 os.chdir() 改变当前目录，到指定目录中。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[worst-passwords]]></title>
      <url>%2F2016%2F05%2F17%2Fworst_passwords%2F</url>
      <content type="text"><![CDATA[123456 password 12345678 1234 pussy 12345 dragon qwerty 696969 mustang letmein baseball master michael football shadow monkey abc123 pass fuckme 6969 jordan harley ranger iwantu jennifer hunter fuck 2000 test batman trustno1 thomas tigger robert access love buster 1234567 soccer hockey killer george sexy andrew charlie superman asshole fuckyou dallas jessica panties pepper 1111 austin william daniel golfer summer heather hammer yankees joshua maggie biteme enter ashley thunder cowboy silver richard fucker orange merlin michelle corvette bigdog cheese matthew 121212 patrick martin freedom ginger blowjob nicole sparky yellow camaro secret dick falcon taylor 111111 131313 123123 bitch hello scooter please porsche guitar chelsea black diamond nascar jackson cameron 654321 computer amanda wizard xxxxxxxx money phoenix mickey bailey knight iceman tigers purple andrea horny dakota aaaaaa player sunshine morgan starwars boomer cowboys edward charles girls booboo coffee xxxxxx bulldog ncc1701 rabbit peanut john johnny gandalf spanky winter brandy compaq carlos tennis james mike brandon fender anthony blowme ferrari cookie chicken maverick chicago joseph diablo sexsex hardcore 666666 willie welcome chris panther yamaha justin banana driver marine angels fishing david maddog hooters wilson butthead dennis fucking captain bigdick chester smokey xavier steven viking snoopy blue eagles winner samantha house miller flower jack firebird butter united turtle steelers tiffany zxcvbn tomcat golf bond007 bear tiger doctor gateway gators angel junior thx1138 porno badboy debbie spider melissa booger 1212 flyers fish porn matrix teens scooby jason walter cumshot boston braves yankee lover barney victor tucker princess mercedes 5150 doggie zzzzzz gunner horney bubba 2112 fred johnson xxxxx tits member boobs donald bigdaddy bronco penis voyager rangers birdie trouble white topgun bigtits bitches green super qazwsx magic lakers rachel slayer scott 2222 asdf video london 7777 marlboro srinivas internet action carter jasper monster teresa jeremy 11111111 bill crystal peter pussies cock beer rocket theman oliver prince beach amateur 7777777 muffin redsox star testing shannon murphy frank hannah dave eagle1 11111 mother nathan raiders steve forever angela viper ou812 jake lovers suckit gregory buddy whatever young nicholas lucky helpme jackie monica midnight college baby cunt brian mark startrek sierra leather 232323 4444 beavis bigcock happy sophie ladies naughty giants booty blonde fucked golden 0 fire sandra pookie packers einstein dolphins 0 chevy winston warrior sammy slut 8675309 zxcvbnm nipples power victoria asdfgh vagina toyota travis hotdog paris rock xxxx extreme redskins erotic dirty ford freddy arsenal access14 wolf nipple iloveyou alex florida eric legend movie success rosebud jaguar great cool cooper 1313 scorpio mountain madison 987654 brazil lauren japan naked squirt stars apple alexis aaaa bonnie peaches jasmine kevin matt qwertyui danielle beaver 4321 4128 runner swimming dolphin gordon casper stupid shit saturn gemini apples august 3333 canada blazer cumming hunting kitty rainbow 112233 arthur cream calvin shaved surfer samson kelly paul mine king racing 5555 eagle hentai newyork little redwings smith sticky cocacola animal broncos private skippy marvin blondes enjoy girl apollo parker qwert time sydney women voodoo magnum juice abgrtyu 777777 dreams maxwell music rush2112 russia scorpion rebecca tester mistress phantom billy 6666 albert the-top-500-worst-passwords]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[emacs]]></title>
      <url>%2F2016%2F03%2F09%2Femacs%2F</url>
      <content type="text"><![CDATA[emacs里所有操作都是LISP指令，包括上下左右移动光标，这意味着什么？ “emacs是一个伪装成编辑器的操作系统”这句话应该就是这么理解吧，所有的操作都是指令，emacs就像操作系统一样，平时不用关注，实际上打交道的都是操作系统上运行的各种程序。emacs也是这样，执行LISP函数就行了，增加各种插件就是增加LISP的函数让你调用而已，各人的配置就是把各种指令绑定快捷键，方便自己使用。emacs的插件功能有执行shell命令，telnet，ftp，文件管理器，收邮件，浏览网页，煮咖啡，擦皮鞋，等等。前段时间又受到黑客与画家书的鼓吹，买了本CLISP的书看，对emacs用的LISP也是越看越顺眼了。 忘掉网上其它的那些教程、手册吧，也忘掉emacs有几百种几千种命令吧。 emacs最简单入门：只要记住一个按键就行了： M-x . 按住Alt键再按x，在窗口最底下出现M-x的提示，在这里输入left-几个字符，按Tab键，出现两行提示 left-char, left-word，再输入一个c，再按Tab键，这时自动补全为left-char，按回车，如果有内容的话，当前的光标点向左移动，就像按了一个向左的方向键一样。 就这样？就这样！ 就这样，发挥你的想象力，想象你现在需要做什么，把它翻译成英文单词，按 M-x，先输入几个字母，按Tab，看是否存在你想象中的指令。要取消当前操作的指令，多按几次ESC键或Ctrl-g键就取消了。 现在假设下emacs有100条指令吧，你如果想做什么事都去执行指令的话，虽然也可以，但是总比不上为常用的指令设置一个快捷键方便。现在看下默认的各种快捷键： 先来看几个简单的 forward-char backward-char previous-line next-line , 很直白的命令，向前后移一个字符或向上下移一行，对应4个方向键。默认绑定的快捷键就是Ctrl加指令首字母 C-f/b/p/n。简洁直白合理极致吧。 复制一些内容到窗口上去，多按几次按键，多按几次手指上的肌肉就不会忘记了。就像用了十多年的五笔输入法一样，看着键盘时一个字也打不也来了，字根键码早忘光了。只有两只手都放在键盘上时，看着汉字，手指自然就打出来了。 再看下 forward-word backward-word ，向前后一个单词，默认绑定快捷键为Alt加指令首字母 M-f/b。也很合理吧。 如果要快速移动到当前行首行尾，或者是一句话的首尾部呢？ move-beginning-of-line move-end-of-line backward-sentence forward-sentence ，默认绑定的快捷键是 C-a/e M-a/e，好像也还算合理吧。 好了，只要理解了emacs里做任何操作都是执行LISP函数，就算是入门了。emacs被称为复杂难学是因为默认设置了很多快捷键，不容易一下记住。现在只要记住用M-x来执行命令，快捷键一律忽视，等熟悉了LISP指令及对应的功能，想为它设置一个快捷键时，再看看默认设置的快捷键是否合你的胃口，改或不改你决定。对emacs感兴趣或者不感兴趣现在就可以决定了。什么学emacs需要很强的耐心那些都是胡扯，我敢打赌只要有好奇心的人就会继续往下看。现在可以打开帮助菜单下的教程，跟着操作一遍，学习一些最常用的快捷键了。多动手，肌肉记忆比大脑记忆好用。 想象一下你使用其它编辑器时使用到的各种功能快捷键，把它和emacs默认设置的快捷键比较一下，哪种设置比较合理。emacs里的各种快捷键设置都是无害的，意思就是你改掉一个快捷键对应的功能，命令却还在，永远可以用M-x来直接执行。如果是其它编辑器就比较麻烦，可能这个操作的功能就找不回来了。 一些默认快捷键C-代表按住Ctrl键 M-代表按住Alt键，也可以用按一下ESC放开代替 最先要记住的M-x &lt;cmd&gt; 输入指令执行，在输入时用Tab可以自动补全或列出项目 C-g 取消当前操作指令 C-h k &lt;key&gt; 查看当前按键绑定的指令及介绍 移动插入点（光标）C-n/p/b/f 到 下一行、上一行、前一字符、后一字符 M-b/f 到 前、后一单词 C-a/e 到 行首、末 M-a/e 到 句首、末 M- 到 文件首、末 C-v/M-v 下、上翻屏 C-l 循环 将当前光标行显示在窗口下、中、上位置 C-u &lt;num&gt; &lt;xx&gt; 重复执行之后的 xx 命令 num 次，不输入num默认为4 C-u C-v 向下滚动4行 编辑Back/C-d 删除 前、后字符 M-Back/M-d 移除 前、后单词 C-k/M-k 移除到 行末、句末 C-/ undo/redo C-x u undo/redo C-w 剪切 C-y 召回（粘贴）（粘贴移除的、复制、剪切的内容） C-c 复制（emacs一般也默认定制了与OS的剪切复制粘贴相同的快捷键） 查找C-s C-s 查找下一个 C-r 查找上一下 C-g 一次返回，二次结束查找 回车 停止到当前查找到的内容 替换M-% 标记M-@ 文件操作C-x C-c 退出emacs C-x C-f 打开文件 C-x C-s 保存文件 C-x C-v 在当前缓冲区重新打开一个文件，可以用于清除undo历史!! C-x 1 最大化当前缓冲，关闭其它 C-x 2/3 垂直、水平创建新缓冲区 C-x o 切换到其它缓冲区 C-x C-b 列出缓冲区 C-x b 提示输入缓冲区名称，切换当前窗口的缓冲区 C-x k 删除当前缓冲区 C-j 换行回车，有些模式下比较直接回车好用，有增加缩进之类的功能 理解一些概念buffer 缓冲区，内存中的数据，打开文件时读入内容到内存，修改后保存才会修改到磁盘上的文件。 window 窗口，缓冲区的一个展示区域 frame OS上的一个emacs程序窗口 mode 模式 mode有主模式，辅助模式，主模式就像vim中设置当前filetype一样，当前编辑的是ruby或者python源代码，根据不同文件类型，设置按Tab缩进时缩进不同的字符数，把不同的词当作关键字时行语法高亮等等，同一时间只能选一个主模式。试着多开几个窗口，执行text-mode ruby-mode python-mode试下。emacs打开文件时会自动根据文件扩展名或内容检查并设置主模式。 辅助模式就是窗口是否要自动换行，是否显示行号等，辅助模式可以多个同时启用。 undo 在 EMACS 中想要将已经做过的动作放弃，以恢复原状。 EMACS 所提供的 undo，可以连续恢复最近使用过的指令。 undo 的顺序是最新使用过的指令最先被 undo ，第二次使用 undo 则恢复第二新的指令，任何指令的输入（除了 undo 本身之外） 都会使指令输入的顺序重整， 这也同时影响 undo 的顺序。 使用 undo 有一个限制，就是 undo 只能 undo 对缓冲区内容造成改变的指令。对于只是改变游标动作的指令，是无法以 undo 来恢复旧观。若所有修改过内容的指令，都以 undo 恢复原状后， 再一次使用 undo 的指令，echo area 会出现如下的讯息：No further undo information. 当使用了 undo 之后，还想要在 redo 这个已被 undo 的动作时， 有一个技巧可以达成如此的效果。 1.首先键入一个不会改变缓冲区内容的指令（如光标移动的指令），使原来 2.存放指令的顺序因新指令的加入而改变。 3.再使用一次 undo 的指令，就可以达到 redo 的效果了。 undo的行为很难描述，示例： 新建一个文件 执行几个修改内容的指令 ， 这时undo历史里有6条记录 undo顺序为654321, 继续undo则提示No further undo information 按下左右方向键（虽然移不动光标），这时undo历史里有12条记录了，前6条undo就变成redo了，顺序123456654321 再按下方向键，undo历史记录数量再翻倍 emacs的undo不会丢失任何操作，你先做一些操作，undo，再做另一些操作，如果是其它编辑器，第一次undo的动作就失踪了，emacs里却一直存在着，原因同上。多试几次就明白了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[my.cnf]]></title>
      <url>%2F2016%2F02%2F15%2Fmy.cnf%2F</url>
      <content type="text"><![CDATA[MySQL配置文件示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518#BEGIN CONFIG INFO#TYPE: SYSTEM#END CONFIG INFO## This is a MySQL example config file for systems with 4GB of memory# running mostly MySQL using InnoDB only tables and performing complex# queries with few connections.# # MySQL programs look for option files in a set of# locations which depend on the deployment platform.# You can copy this option file to one of those# locations. For information about these locations, see:# http://dev.mysql.com/doc/mysql_5.6/en/option-files.html## In this file, you can use all long options that a program supports.# If you want to know which options a program supports, run the program# with the &quot;--help&quot; option.## More detailed information about the individual options can also be# found in the manual.### The following options will be read by MySQL client applications.# Note that only client applications shipped by MySQL are guaranteed# to read this section. If you want your own MySQL client program to# honor these values, you need to specify it as an option during the# MySQL client library initialization.#[client]#password = your_passwordport = 3306socket = /var/run/mysqld/mysqld.sock# Here follows entries for some specific programs# The MySQL server[mysqld]user = mysqlport = 3306pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockbasedir = /db/mysql_5.6datadir = /db/mysql_5.6/dataexplicit_defaults_for_timestamp=true#bind-address = 127.0.0.1# back_log is the number of connections the operating system can keep in# the listen queue, before the MySQL connection manager thread has# processed them. If you have a very high connection rate and experience# &quot;connection refused&quot; errors, you might need to increase this value.# Check your OS documentation for the maximum value of this parameter.# Attempting to set back_log higher than your operating system limit# will have no effect.back_log = 500# Don&apos;t listen on a TCP/IP port at all. This can be a security# enhancement, if all processes that need to connect to mysqld run# on the same host. All interaction with mysqld must be made via Unix# sockets or named pipes.# Note that using this option without enabling named pipes on Windows# (via the &quot;enable-named-pipe&quot; option) will render mysqld useless!#skip-networkingskip-name-resolve# The maximum amount of concurrent sessions the MySQL server will# allow. One of these connections will be reserved for a user with# SUPER privileges to allow the administrator to login even if the# connection limit has been reached.max_connections = 1000# Maximum amount of errors allowed per host. If this limit is reached,# the host will be blocked from connecting to the MySQL server until# &quot;FLUSH HOSTS&quot; has been run or the server was restarted. Invalid# passwords and other errors during the connect phase result in# increasing this value. See the &quot;Aborted_connects&quot; status variable for# global counter.max_connect_errors = 100# The number of open tables for all threads. Increasing this value# increases the number of file descriptors that mysqld requires.# Therefore you have to make sure to set the amount of open files# allowed to at least 4096 in the variable &quot;open-files-limit&quot; in# section [mysqld_safe]table_open_cache = 2048# Enable external file level locking. Enabled file locking will have a# negative impact on performance, so only use it in case you have# multiple database instances running on the same files (note some# restrictions still apply!) or if you use other software relying on# locking MyISAM tables on file level.#external-lockingskip-external-locking# The maximum size of a query packet the server can handle as well as# maximum query size server can process (Important when working with# large BLOBs). enlarged dynamically, for each connection.max_allowed_packet = 512M# The size of the cache to hold the SQL statements for the binary log# during a transaction. If you often use big, multi-statement# transactions you can increase this value to get more performance. All# statements from transactions are buffered in the binary log cache and# are being written to the binary log at once after the COMMIT. If the# transaction is larger than this value, temporary file on disk is used# instead. This buffer is allocated per connection on first update# statement in transactionbinlog_cache_size = 10M# Maximum allowed size for a single HEAP (in memory) table. This option# is a protection against the accidential creation of a very large HEAP# table which could otherwise use up all memory resources.max_heap_table_size = 64M# Size of the buffer used for doing full table scans.# Allocated per thread, if a full scan is needed.read_buffer_size = 2M# When reading rows in sorted order after a sort, the rows are read# through this buffer to avoid disk seeks. You can improve ORDER BY# performance a lot, if set this to a high value.# Allocated per thread, when needed.read_rnd_buffer_size = 16M# Sort buffer is used to perform sorts for some ORDER BY and GROUP BY# queries. If sorted data does not fit into the sort buffer, a disk# based merge sort is used instead - See the &quot;Sort_merge_passes&quot;# status variable. Allocated per thread if sort is needed.sort_buffer_size = 8M# This buffer is used for the optimization of full JOINs (JOINs without# indexes). Such JOINs are very bad for performance in most cases# anyway, but setting this variable to a large value reduces the# performance impact. See the &quot;Select_full_join&quot; status variable for a# count of full JOINs. Allocated per thread if full join is foundjoin_buffer_size = 8M# How many threads we should keep in a cache for reuse. When a client# disconnects, the client&apos;s threads are put in the cache if there aren&apos;t# more than thread_cache_size threads from before. This greatly reduces# the amount of thread creations needed if you have a lot of new# connections. (Normally this doesn&apos;t give a notable performance# improvement if you have a good thread implementation.)#thread_cache_size = 8# This permits the application to give the threads system a hint for the# desired number of threads that should be run at the same time. This# value only makes sense on systems that support the thread_concurrency()# function call (Sun Solaris, for example).# You should try [number of CPUs]*(2..4) for thread_concurrency#thread_concurrency = 8# Query cache is used to cache SELECT results and later return them# without actual executing the same query once again. Having the query# cache enabled may result in significant speed improvements, if your# have a lot of identical queries and rarely changing tables. See the# &quot;Qcache_lowmem_prunes&quot; status variable to check if the current value# is high enough for your load.# Note: In case your tables change very often or if your queries are# textually different every time, the query cache may result in a# slowdown instead of a performance improvement.query_cache_type= 0query_cache_size = 0# Only cache result sets that are smaller than this limit. This is to# protect the query cache of a very large result set overwriting all# other query results.#query_cache_limit = 2M# Minimum word length to be indexed by the full text search index.# You might wish to decrease it if you need to search for shorter words.# Note that you need to rebuild your FULLTEXT index, after you have# modified this value.ft_min_word_len = 4# If your system supports the memlock() function call, you might want to# enable this option while running MySQL to keep it locked in memory and# to avoid potential swapping out in case of high memory pressure. Good# for performance.#memlock# Table type which is used by default when creating new tables, if not# specified differently during the CREATE TABLE statement.default-storage-engine = INNODB# Thread stack size to use. This amount of memory is always reserved at# connection time. MySQL itself usually needs no more than 64K of# memory, while if you use your own stack hungry UDF functions or your# OS requires more stack for some operations, you might need to set this# to a higher value.thread_stack = 192K# Set the default transaction isolation level. Levels available are:# READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ, SERIALIZABLEtransaction_isolation = REPEATABLE-READ# Maximum size for internal (in-memory) temporary tables. If a table# grows larger than this value, it is automatically converted to disk# based table This limitation is for a single table. There can be many# of them.tmp_table_size = 64M# Enable binary logging. This is required for acting as a MASTER in a# replication configuration. You also need the binary log if you need# the ability to do point in time recovery from your latest backup.log-bin = /db/mysql_5.6/logs/mysql-bin# binary logging format - mixed recommendedbinlog_format=mixedgeneral_log = 0general_log_file = /db/mysql_5.6/logs/mysql_general.log# If you&apos;re using replication with chained slaves (A-&gt;B-&gt;C), you need to# enable this option on server B. It enables logging of updates done by# the slave thread into the slave&apos;s binary log.#log_slave_updates# Enable the full query log. Every query (even ones with incorrect# syntax) that the server receives will be logged. This is useful for# debugging, it is usually disabled in production use.#log# Print warnings to the error log file. If you have any problem with# MySQL you should enable logging of warnings and examine the error log# for possible explanations. #log_warnings# Log slow queries. Slow queries are queries which take more than the# amount of time defined in &quot;long_query_time&quot; or which do not use# indexes well, if log_short_format is not enabled. It is normally good idea# to have this turned on if you frequently add new queries to the# system.##error loglog-error=/db/mysql_5.6/logs/error.logslow_query_log = 1slow_query_log_file = /db/mysql_5.6/logs/slow-query.log# All queries taking more than this amount of time (in seconds) will be# trated as slow. Do not use &quot;1&quot; as a value here, as this will result in# even very fast queries being logged from time to time (as MySQL# currently measures time with second accuracy only).long_query_time = 5log-queries-not-using-indexes# *** Replication related settings # Unique server identification number between 1 and 2^32-1. This value# is required for both master and slave hosts. It defaults to 1 if# &quot;master-host&quot; is not set, but will MySQL will not function as a master# if it is omitted.server-id = 2481# Replication Slave (comment out master section to use this)## To configure this host as a replication slave, you can choose between# two methods :## 1) Use the CHANGE MASTER TO command (fully described in our manual) -# the syntax is:## CHANGE MASTER TO MASTER_HOST=&lt;host&gt;, MASTER_PORT=&lt;port&gt;,# MASTER_USER=&lt;user&gt;, MASTER_PASSWORD=&lt;password&gt; ;## where you replace &lt;host&gt;, &lt;user&gt;, &lt;password&gt; by quoted strings and# &lt;port&gt; by the master&apos;s port number (3306 by default).## Example:## CHANGE MASTER TO MASTER_HOST=&apos;125.564.12.1&apos;, MASTER_PORT=3306,# MASTER_USER=&apos;joe&apos;, MASTER_PASSWORD=&apos;secret&apos;;## OR## 2) Set the variables below. However, in case you choose this method, then# start replication for the first time (even unsuccessfully, for example# if you mistyped the password in master-password and the slave fails to# connect), the slave will create a master.info file, and any later# changes in this file to the variable values below will be ignored and# overridden by the content of the master.info file, unless you shutdown# the slave server, delete master.info and restart the slaver server.# For that reason, you may want to leave the lines below untouched# (commented) and instead use CHANGE MASTER TO (see above)## required unique id between 2 and 2^32 - 1# (and different from the master)# defaults to 2 if master-host is set# but will not function as a slave if omitted#server-id = 2## The replication master for this slave - required#master-host = &lt;hostname&gt;## The username the slave will use for authentication when connecting# to the master - required#master-user = &lt;username&gt;## The password the slave will authenticate with when connecting to# the master - required#master-password = &lt;password&gt;## The port the master is listening on.# optional - defaults to 3306#master-port = &lt;port&gt;# Make the slave read-only. Only users with the SUPER privilege and the# replication slave thread will be able to modify data on it. You can# use this to ensure that no applications will accidently modify data on# the slave instead of the master#read_only#*** MyISAM Specific options# Size of the Key Buffer, used to cache index blocks for MyISAM tables.# Do not set it larger than 30% of your available memory, as some memory# is also required by the OS to cache rows. Even if you&apos;re not using# MyISAM tables, you should still set it to 8-64M as it will also be# used for internal temporary disk tables.key_buffer_size = 32M# MyISAM uses special tree-like cache to make bulk inserts (that is,# INSERT ... SELECT, INSERT ... VALUES (...), (...), ..., and LOAD DATA# INFILE) faster. This variable limits the size of the cache tree in# bytes per thread. Setting it to 0 will disable this optimisation. Do# not set it larger than &quot;key_buffer_size&quot; for optimal performance.# This buffer is allocated when a bulk insert is detected.bulk_insert_buffer_size = 64M# This buffer is allocated when MySQL needs to rebuild the index in# REPAIR, OPTIMIZE, ALTER table statements as well as in LOAD DATA INFILE# into an empty table. It is allocated per thread so be careful with# large settings.myisam_sort_buffer_size = 128M# The maximum size of the temporary file MySQL is allowed to use while# recreating the index (during REPAIR, ALTER TABLE or LOAD DATA INFILE.# If the file-size would be bigger than this, the index will be created# through the key cache (which is slower).myisam_max_sort_file_size = 10G# If a table has more than one index, MyISAM can use more than one# thread to repair them by sorting in parallel. This makes sense if you# have multiple CPUs and plenty of memory.myisam_repair_threads = 1# Automatically check and repair not properly closed MyISAM tables.myisam_recover# *** INNODB Specific options ***innodb_file_per_table=1# Use this option if you have a MySQL server with InnoDB support enabled# but you do not plan to use it. This will save memory and disk space# and speed up some things.#skip-innodb# Additional memory pool that is used by InnoDB to store metadata# information. If InnoDB requires more memory for this purpose it will# start to allocate it from the OS. As this is fast enough on most# recent operating systems, you normally do not need to change this# value. SHOW INNODB STATUS will display the current amount used.innodb_additional_mem_pool_size = 16M# InnoDB, unlike MyISAM, uses a buffer pool to cache both indexes and# row data. The bigger you set this the less disk I/O is needed to# access data in tables. On a dedicated database server you may set this# parameter up to 80% of the machine physical memory size. Do not set it# too large, though, because competition of the physical memory may# cause paging in the operating system. Note that on 32bit systems you# might be limited to 2-3.5G of user level memory per process, so do not# set it too high.innodb_buffer_pool_size = 25G# InnoDB stores data in one or more data files forming the tablespace.# If you have a single logical drive for your data, a single# autoextending file would be good enough. In other cases, a single file# per device is often a good choice. You can configure InnoDB to use raw# disk partitions as well - please refer to the manual for more info# about this.innodb_data_file_path = ibdata1:2048M:autoextend# Set this option if you would like the InnoDB tablespace files to be# stored in another location. By default this is the MySQL datadir.innodb_data_home_dir = /db/mysql_5.6/data# Number of IO threads to use for async IO operations. This value is# hardcoded to 4 on Unix, but on Windows disk I/O may benefit from a# larger number.innodb_file_io_threads = 4# If you run into InnoDB tablespace corruption, setting this to a nonzero# value will likely help you to dump your tables. Start from value 1 and# increase it until you&apos;re able to dump the table successfully.#innodb_force_recovery=1# Number of threads allowed inside the InnoDB kernel. The optimal value# depends highly on the application, hardware as well as the OS# scheduler properties. A too high value may lead to thread thrashing.innodb_thread_concurrency = 16# If set to 1, InnoDB will flush (fsync) the transaction logs to the# disk at each commit, which offers full ACID behavior. If you are# willing to compromise this safety, and you are running small# transactions, you may set this to 0 or 2 to reduce disk I/O to the# logs. Value 0 means that the log is only written to the log file and# the log file flushed to disk approximately once per second. Value 2# means the log is written to the log file at each commit, but the log# file is only flushed to disk approximately once per second.innodb_flush_log_at_trx_commit = 2# Speed up InnoDB shutdown. This will disable InnoDB to do a full purge# and insert buffer merge on shutdown. It may increase shutdown time a# lot, but InnoDB will have to do it on the next startup instead.#innodb_fast_shutdown# The size of the buffer InnoDB uses for buffering log data. As soon as# it is full, InnoDB will have to flush it to disk. As it is flushed# once per second anyway, it does not make sense to have it very large# (even with long transactions). innodb_log_buffer_size = 10M# Size of each log file in a log group. You should set the combined size# of log files to about 25%-100% of your buffer pool size to avoid# unneeded buffer pool flush activity on log file overwrite. However,# note that a larger logfile size will increase the time needed for the# recovery process.innodb_log_file_size = 256M# Total number of files in the log group. A value of 2-3 is usually good# enough.innodb_log_files_in_group = 2# Location of the InnoDB log files. Default is the MySQL datadir. You# may wish to point it to a dedicated hard drive or a RAID1 volume for# improved performance#innodb_log_group_home_dir# Maximum allowed percentage of dirty pages in the InnoDB buffer pool.# If it is reached, InnoDB will start flushing them out agressively to# not run out of clean pages at all. This is a soft limit, not# guaranteed to be held.innodb_max_dirty_pages_pct = 90# The flush method InnoDB will use for Log. The tablespace always uses# doublewrite flush logic. The default value is &quot;fdatasync&quot;, another# option is &quot;O_DSYNC&quot;.#innodb_flush_method=O_DSYNC# How long an InnoDB transaction should wait for a lock to be granted# before being rolled back. InnoDB automatically detects transaction# deadlocks in its own lock table and rolls back the transaction. If you# use the LOCK TABLES command, or other transaction-safe storage engines# than InnoDB in the same transaction, then a deadlock may arise which# InnoDB cannot notice. In cases like this the timeout is useful to# resolve the situation.innodb_lock_wait_timeout = 120# * Security Features## Read the manual, too, if you want chroot!# chroot = /var/lib/mysql/## For generating SSL certificates I recommend the OpenSSL GUI &quot;tinyca&quot;.## ssl-ca=/etc/mysql/cacert.pem# ssl-cert=/etc/mysql/server-cert.pem# ssl-key=/etc/mysql/server-key.pemnet_read_timeout = 600net_write_timeout = 600lower_case_table_names=1[mysqldump]# Do not buffer the whole result set in memory before writing it to# file. Required for dumping very large tablesquickmax_allowed_packet = 16M[mysql]no-auto-rehash# Only allow UPDATEs and DELETEs that use keys.#safe-updates[myisamchk]key_buffer_size = 512Msort_buffer_size = 512Mread_buffer = 8Mwrite_buffer = 8M[mysqlhotcopy]interactive-timeout[mysqld_safe]# Increase the amount of open files allowed per process. Warning: Make# sure you have set the global system limit high enough! The high value# is required for a large number of opened tables#open-files-limit = 20480socket = /var/run/mysqld/mysqld.sock#nice = 0]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[parted]]></title>
      <url>%2F2015%2F07%2F17%2Fparted%2F</url>
      <content type="text"><![CDATA[parted –helpUsage: parted [OPTION]… [DEVICE [COMMAND [PARAMETERS]…]…]Apply COMMANDs with PARAMETERS to DEVICE. If no COMMAND(s) are given, run ininteractive mode. OPTIONs:123456-h, --help displays this help message-l, --list lists partition layout on all block devices-m, --machine displays machine parseable output-s, --script never prompts for user intervention-v, --version displays the version-a, --align=[none|cyl|min|opt] alignment for new partitions COMMANDs:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071 align-check TYPE N check partition N for TYPE(min|opt) alignment check NUMBER do a simple check on the file system cp [FROM-DEVICE] FROM-NUMBER TO-NUMBER copy file system to another partition help [COMMAND] print general help, or help on COMMAND mklabel,mktable LABEL-TYPE create a new disklabel (partition table) label-type malable Create a new disklabel (partition table) of label-type. label- type should be one of &quot;bsd&quot;, &quot;dvh&quot;, &quot;gpt&quot;, &quot;loop&quot;, &quot;mac&quot;, &quot;msdos&quot;, &quot;pc98&quot;, or &quot;sun&quot;. mktable mbr gpt mkfs NUMBER FS-TYPE make a FS-TYPE file system on partition NUMBER partition fs-type Make a filesystem fs-type on partition. fs-type can be one of &quot;fat16&quot;, &quot;fat32&quot;, &quot;ext2&quot;, &quot;linux-swap&quot;, or &quot;reiserfs&quot;. mkpart PART-TYPE [FS-TYPE] START END make a partition mkpartfs PART-TYPE FS-TYPE START END make a partition with a file system Make a part-type partition with filesystem fs-type beginning at start and ending at end (by default in megabytes). Using this command is discouraged. Instead use mkpart to create an empty partition, and then use external tools like mke2fs(8) to create the filesystem. move NUMBER START END move partition NUMBER name NUMBER NAME name partition NUMBER as NAME print [devices|free|list,all|NUMBER] display the partition table, available devices, free space, all found partitions, or a particular partition quit exit program rescue START END rescue a lost partition near START and END resize NUMBER START END resize partition NUMBER and its file system rm NUMBER delete partition NUMBER select DEVICE choose the device to edit set NUMBER FLAG STATE change the FLAG on partition NUMBER toggle [NUMBER [FLAG]] toggle the state of FLAG on partition NUMBER unit UNIT set the default unit to UNIT version display the version number andcopyright information of GNU Parted]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[openssh]]></title>
      <url>%2F2015%2F07%2F17%2Fopenssh%2F</url>
      <content type="text"><![CDATA[/etc/ssh/ssh_config 文件123456789101112131415161718192021222324252627282930313233# Site-wide defaults for various options Host *&quot;Host&quot;只对匹配后面字串的计算机有效，“*”表示所有的计算机。从该项格式前置一些可以看出，这是一个类似于全局的选项，表示下面缩进的选项都适用于该设置，可以指定某计算机替换*号使下面选项只针对该算机器生效。ForwardAgent no&quot;ForwardAgent&quot;设置连接是否经过验证代理（如果存在）转发给远程计算机。ForwardX11 no&quot;ForwardX11&quot;设置X11连接是否被自动重定向到安全的通道和显示集（DISPLAY set）。RhostsAuthentication no&quot;RhostsAuthentication&quot;设置是否使用基于rhosts的安全验证。RhostsRSAAuthentication no&quot;RhostsRSAAuthentication&quot;设置是否使用用RSA算法的基于rhosts的安全验证。RSAAuthentication yes&quot;RSAAuthentication&quot;设置是否使用RSA算法进行安全验证。PasswordAuthentication yes&quot;PasswordAuthentication&quot;设置是否使用口令验证。FallBackToRsh no&quot;FallBackToRsh&quot;设置如果用ssh连接出现错误是否自动使用rsh，由于rsh并不安全，所以此选项应当设置为&quot;no&quot;。UseRsh no&quot;UseRsh&quot;设置是否在这台计算机上使用&quot;rlogin/rsh&quot;，原因同上，设为&quot;no&quot;。BatchMode no&quot;BatchMode&quot;：批处理模式，一般设为&quot;no&quot;；如果设为&quot;yes&quot;，交互式输入口令的提示将被禁止，这个选项对脚本文件和批处理任务十分有用。CheckHostIP yes&quot;CheckHostIP&quot;设置ssh是否查看连接到服务器的主机的IP地址以防止DNS欺骗。建议设置为&quot;yes&quot;。StrictHostKeyChecking no&quot;StrictHostKeyChecking&quot;如果设为&quot;yes&quot;，ssh将不会自动把计算机的密匙加入&quot;$HOME/.ssh/known_hosts&quot;文件，且一旦计算机的密匙发生了变化，就拒绝连接。IdentityFile ~/.ssh/identity&quot;IdentityFile&quot;设置读取用户的RSA安全验证标识。Port 22&quot;Port&quot;设置连接到远程主机的端口，ssh默认端口为22。Cipher blowfish“Cipher”设置加密用的密钥，blowfish可以自己随意设置。EscapeChar ~“EscapeChar”设置escape字符。 /etc/ssh/sshd_config 文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293# 关于 SSH Server 的整体设定，包含使用的 port 啦，以及使用的密码演算方式Port 22 # SSH 预设使用 22 这个 port，您也可以使用多的 port ！ # 亦即重复使用 port 这个设定项目即可！Protocol 2,1 # 选择的 SSH 协议版本，可以是 1 也可以是 2 ， # 如果要同时支持两者，就必须要使用 2,1 这个分隔了！#ListenAddress 0.0.0.0 # 监听的主机适配卡！举个例子来说，如果您有两个 IP， # 分别是 192.168.0.100 及 192.168.2.20 ，那么只想要 # 开放 192.168.0.100 时，就可以写如同下面的样式：ListenAddress 192.168.0.100 # 只监听来自 192.168.0.100 这个 IP 的SSH联机。 # 如果不使用设定的话，则预设所有接口均接受 SSHPidFile /var/run/sshd.pid # 可以放置 SSHD 这个 PID 的档案！左列为默认值LoginGraceTime 600 # 当使用者连上 SSH server 之后，会出现输入密码的画面， # 在该画面中，在多久时间内没有成功连上 SSH server ， # 就断线！时间为秒！Compression yes # 是否可以使用压缩指令？当然可以啰！ # 主机的 Private Key 放置的档案，预设使用下面的档案即可！HostKey /etc/ssh/ssh_host_key # SSH version 1 使用的私钥HostKey /etc/ssh/ssh_host_rsa_key # SSH version 2 使用的 RSA 私钥HostKey /etc/ssh/ssh_host_dsa_key # SSH version 2 使用的 DSA 私钥# 关于 version 1 的一些设定！KeyRegenerationInterval 3600 # 由前面联机的说明可以知道， version 1 会使用 # server 的 Public Key ，那么如果这个 Public # Key 被偷的话，岂不完蛋？所以需要每隔一段时间 # 来重新建立一次！这里的时间为秒！ServerKeyBits 768 # 没错！这个就是 Server key 的长度！# 关于登录文件的讯息数据放置与 daemon 的名称！SyslogFacility AUTH # 当有人使用 SSH 登入系统的时候，SSH会记录资 # 讯，这个信息要记录在什么 daemon name 底下？ # 预设是以 AUTH 来设定的，即是 /var/log/secure # 里面！什么？忘记了！回到 Linux 基础去翻一下 # 其它可用的 daemon name 为：DAEMON,USER,AUTH, # LOCAL0,LOCAL1,LOCAL2,LOCAL3,LOCAL4,LOCAL5,LogLevel INFO # 登录记录的等级！嘿嘿！任何讯息！ # 同样的，忘记了就回去参考！# 安全设定项目！极重要！# 登入设定部分PermitRootLogin no # 是否允许 root 登入！预设是允许的，但是建议设定成 no！UserLogin no # 在 SSH 底下本来就不接受 login 这个程序的登入！StrictModes yes # 当使用者的 host key 改变之后，Server 就不接受联机， # 可以抵挡部分的木马程序！#RSAAuthentication yes # 是否使用纯的 RSA 认证！？仅针对 version 1 ！PubkeyAuthentication yes # 是否允许 Public Key ？当然允许啦！只有 version 2AuthorizedKeysFile .ssh/authorized_keys # 上面这个在设定若要使用不需要密码登入的账号时，那么那个 # 账号的存放档案所在档名！# 认证部分RhostsAuthentication no # 本机系统不止使用 .rhosts ，因为仅使用 .rhosts 太 # 不安全了，所以这里一定要设定为 no ！IgnoreRhosts yes # 是否取消使用 ~/.ssh/.rhosts 来做为认证！当然是！RhostsRSAAuthentication no # 这个选项是专门给 version 1 用的，使用 rhosts 档案在 # /etc/hosts.equiv配合 RSA 演算方式来进行认证！不要使用HostbasedAuthentication no # 这个项目与上面的项目类似，不过是给 version 2 使用的！IgnoreUserKnownHosts no # 是否忽略家目录内的 ~/.ssh/known_hosts 这个档案所记录 # 的主机内容？当然不要忽略，所以这里就是 no 啦！PasswordAuthentication yes # 密码验证当然是需要的！所以这里写 yes 啰！PermitEmptyPasswords no # 若上面那一项如果设定为 yes 的话，这一项就最好设定 # 为 no ，这个项目在是否允许以空的密码登入！当然不许！ChallengeResponseAuthentication yes # 挑战任何的密码认证！所以，任何 login.conf # 规定的认证方式，均可适用！#PAMAuthenticationViaKbdInt yes # 是否启用其它的 PAM 模块！启用这个模块将会 # 导致 PasswordAuthentication 设定失效！ # 与 Kerberos 有关的参数设定！因为我们没有 Kerberos 主机，所以底下不用设定！#KerberosAuthentication no#KerberosOrLocalPasswd yes#KerberosTicketCleanup yes#KerberosTgtPassing no # 底下是有关在 X-Window 底下使用的相关设定！X11Forwarding yes#X11DisplayOffset 10#X11UseLocalhost yes# 登入后的项目：PrintMotd no # 登入后是否显示出一些信息呢？例如上次登入的时间、地点等 # 等，预设是 yes ，但是，如果为了安全，可以考虑改为 no ！PrintLastLog yes # 显示上次登入的信息！可以啊！预设也是 yes ！KeepAlive yes # 一般而言，如果设定这项目的话，那么 SSH Server 会传送 # KeepAlive 的讯息给 Client 端，以确保两者的联机正常！ # 在这个情况下，任何一端死掉后， SSH 可以立刻知道！而不会 # 有僵尸程序的发生！UsePrivilegeSeparation yes # 使用者的权限设定项目！就设定为 yes 吧！MaxStartups 10 # 同时允许几个尚未登入的联机画面？当我们连上 SSH ， # 但是尚未输入密码时，这个时候就是我们所谓的联机画面啦！ # 在这个联机画面中，为了保护主机，所以需要设定最大值， # 预设最多十个联机画面，而已经建立联机的不计算在这十个当中# 关于使用者抵挡的设定项目：DenyUsers * # 设定受抵挡的使用者名称，如果是全部的使用者，那就是全部 # 挡吧！若是部分使用者，可以将该账号填入！例如下列！DenyUsers testDenyGroups test # 与 DenyUsers 相同！仅抵挡几个群组而已！# 5. 关于 SFTP 服务的设定项目！Subsystem sftp /usr/lib/ssh/sftp-server]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[find]]></title>
      <url>%2F2015%2F06%2F19%2Ffind%2F</url>
      <content type="text"><![CDATA[find命令用来在指定目录下查找文件。任何位于参数之前的字符串都将被视为欲查找的目录名。如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示。 语法 find(选项)(参数)选项12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455-amin&lt;分钟&gt;：查找在指定时间曾被存取过的文件或目录，单位以分钟计算； -anewer&lt;参考文件或目录&gt;：查找其存取时间较指定文件或目录的存取时间更接近现在的文件或目录； -atime&lt;24小时数&gt;：查找在指定时间曾被存取过的文件或目录，单位以24小时计算； -cmin&lt;分钟&gt;：查找在指定时间之时被更改过的文件或目录； -cnewer&lt;参考文件或目录&gt;查找其更改时间较指定文件或目录的更改时间更接近现在的文件或目录； -ctime&lt;24小时数&gt;：查找在指定时间之时被更改的文件或目录，单位以24小时计算； -daystart：从本日开始计算时间； -depth：从指定目录下最深层的子目录开始查找； -expty：寻找文件大小为0 Byte的文件，或目录下没有任何子目录或文件的空目录； -exec&lt;执行指令&gt;：假设find指令的回传值为True，就执行该指令； -false：将find指令的回传值皆设为False； -fls&lt;列表文件&gt;：此参数的效果和指定“-ls”参数类似，但会把结果保存为指定的列表文件； -follow：排除符号连接； -fprint&lt;列表文件&gt;：此参数的效果和指定“-print”参数类似，但会把结果保存成指定的列表文件； -fprint0&lt;列表文件&gt;：此参数的效果和指定“-print0”参数类似，但会把结果保存成指定的列表文件； -fprintf&lt;列表文件&gt;&lt;输出格式&gt;：此参数的效果和指定“-printf”参数类似，但会把结果保存成指定的列表文件； -fstype&lt;文件系统类型&gt;：只寻找该文件系统类型下的文件或目录； -gid&lt;群组识别码&gt;：查找符合指定之群组识别码的文件或目录； -group&lt;群组名称&gt;：查找符合指定之群组名称的文件或目录； -help或——help：在线帮助； -ilname&lt;范本样式&gt;：此参数的效果和指定“-lname”参数类似，但忽略字符大小写的差别； -iname&lt;范本样式&gt;：此参数的效果和指定“-name”参数类似，但忽略字符大小写的差别； -inum：查找符合指定的inode编号的文件或目录； -ipath&lt;范本样式&gt;：此参数的效果和指定“-path”参数类似，但忽略字符大小写的差别； -iregex&lt;范本样式&gt;：此参数的效果和指定“-regexe”参数类似，但忽略字符大小写的差别； -links&lt;连接数目&gt;：查找符合指定的硬连接数目的文件或目录； -iname&lt;范本样式&gt;：指定字符串作为寻找符号连接的范本样式； -ls：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出； -maxdepth&lt;目录层级&gt;：设置最大目录层级； -mindepth&lt;目录层级&gt;：设置最小目录层级； -mmin&lt;分钟&gt;：查找在指定时间曾被更改过的文件或目录，单位以分钟计算； -mount：此参数的效果和指定“-xdev”相同； -mtime&lt;24小时数&gt;：查找在指定时间曾被更改过的文件或目录，单位以24小时计算； -name&lt;范本样式&gt;：指定字符串作为寻找文件或目录的范本样式； -newer&lt;参考文件或目录&gt;：查找其更改时间较指定文件或目录的更改时间更接近现在的文件或目录； -nogroup：找出不属于本地主机群组识别码的文件或目录； -noleaf：不去考虑目录至少需拥有两个硬连接存在； -nouser：找出不属于本地主机用户识别码的文件或目录； -ok&lt;执行指令&gt;：此参数的效果和指定“-exec”类似，但在执行指令之前会先询问用户，若回答“y”或“Y”，则放弃执行命令； -path&lt;范本样式&gt;：指定字符串作为寻找目录的范本样式； -perm&lt;权限数值&gt;：查找符合指定的权限数值的文件或目录； -print：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出。格式为每列一个名称，每个名称前皆有“./”字符串； -print0：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出。格式为全部的名称皆在同一行； -printf&lt;输出格式&gt;：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出。格式可以自行指定； -prune：不寻找字符串作为寻找文件或目录的范本样式; -regex&lt;范本样式&gt;：指定字符串作为寻找文件或目录的范本样式； -size&lt;文件大小&gt;：查找符合指定的文件大小的文件； -true：将find指令的回传值皆设为True； -typ&lt;文件类型&gt;：只寻找符合指定的文件类型的文件； -uid&lt;用户识别码&gt;：查找符合指定的用户识别码的文件或目录； -used&lt;日数&gt;：查找文件或目录被更改之后在指定时间曾被存取过的文件或目录，单位以日计算； -user&lt;拥有者名称&gt;：查找符和指定的拥有者名称的文件或目录； -version或——version：显示版本信息； -xdev：将范围局限在先行的文件系统中； -xtype&lt;文件类型&gt;：此参数的效果和指定“-type”参数类似，差别在于它针对符号连接检查。 参数列出当前目录及子目录下所有文件和文件夹find . 在/home目录下查找以.txt结尾的文件名find /home -name &quot;*.txt&quot; 同上，但忽略大小写find /home -iname &quot;*.txt&quot; 当前目录及子目录下查找所有以.txt和.pdf结尾的文件find . \( -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; \) 或 find . -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; 匹配文件路径或者文件find /usr/ -path &quot;*local*&quot; 基于正则表达式匹配文件路径find . -regex &quot;.*\(\.txt\|\.pdf\)$&quot; 同上，但忽略大小写find . -iregex &quot;.*\(\.txt\|\.pdf\)$&quot; 否定参数找出/home下不是以.txt结尾的文件find /home ! -name &quot;*.txt&quot; 根据文件类型进行搜索find . -type 类型参数 类型参数列表：1234567f 普通文件 l 符号连接 d 目录 c 字符设备 b 块设备 s 套接字 p Fifo 基于目录深度搜索向下最大深度限制为3find . -maxdepth 3 -type f 搜索出深度距离当前目录至少2个子目录的所有文件find . -mindepth 2 -type f 根据文件时间戳进行搜索find . -type f 时间戳 UNIX/Linux文件系统每个文件都有三种时间戳:123访问时间（-atime/天，-amin/分钟）：用户最近一次访问时间。 修改时间（-mtime/天，-mmin/分钟）：文件最后一次修改时间。 变化时间（-ctime/天，-cmin/分钟）：文件数据元（例如权限等）最后一次修改时间。 搜索最近七天内被访问过的所有文件find . -type f -atime -7 搜索恰好在七天前被访问过的所有文件find . -type f -atime 7 搜索超过七天内被访问过的所有文件find . -type f -atime +7 搜索访问时间超过10分钟的所有文件find . -type f -amin +10 找出比file.log修改时间更长的所有文件find . -type f -newer file.log 根据文件大小进行匹配find . -type f -size 文件大小单元 文件大小单元：123456b —— 块（512字节） c —— 字节 w —— 字（2字节） k —— 千字节 M —— 兆字节 G —— 吉字节 搜索大于10KB的文件find . -type f -size +10k 搜索小于10KB的文件find . -type f -size -10k 搜索等于10KB的文件find . -type f -size 10k 删除匹配文件删除当前目录下所有.txt文件find . -type f -name &quot;*.txt&quot; -delete 根据文件权限/所有权进行匹配当前目录下搜索出权限为777的文件find . -type f -perm 777 找出当前目录下权限不是644的php文件find . -type f -name &quot;*.php&quot; ! -perm 644 找出当前目录用户tom拥有的所有文件find . -type f -user tom 找出当前目录用户组sunk拥有的所有文件find . -type f -group sunk 借助-exec选项与其他命令结合使用找出当前目录下所有root的文件，并把所有权更改为用户tomfind .-type f -user root -exec chown tom {} \; 上例中，{} 用于与-exec选项结合使用来匹配所有文件，然后会被替换为相应的文件名。 找出自己家目录下所有的.txt文件并删除find $HOME/. -name &quot;*.txt&quot; -ok rm {} \; 上例中，-ok和-exec行为一样，不过它会给出提示，是否执行相应的操作。 查找当前目录下所有.txt文件并把他们拼接起来写入到all.txt文件中find . -type f -name &quot;*.txt&quot; -exec cat {} \;&gt; all.txt 将30天前的.log文件移动到old目录中find . -type f -mtime +30 -name &quot;*.log&quot; -exec cp {} old \; 找出当前目录下所有.txt文件并以“File:文件名”的形式打印出来find . -type f -name &quot;*.txt&quot; -exec printf &quot;File: %s\n&quot; {} \; 因为单行命令中-exec参数中无法使用多个命令，以下方法可以实现在-exec之后接受多条命令-exec ./text.sh {} \; 搜索但跳出指定的目录 查找当前目录或者子目录下所有.txt文件，但是跳过子目录skfind . -path &quot;./sk&quot; -prune -o -name &quot;*.txt&quot; -print find其他技巧收集 要列出所有长度为零的文件find . -empty]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[useradd]]></title>
      <url>%2F2015%2F06%2F09%2Fuser%2F</url>
      <content type="text"><![CDATA[useradd –helpUsage: useradd [options] LOGINOptions:-b, --base-dir BASE_DIR base directory for the home directory of the new account -c, --comment COMMENT GECOS field of the new account -d, --home-dir HOME_DIR home directory of the new account -D, --defaults print or change default useradd configuration 查看预设值 -e, --expiredate EXPIRE_DATE expiration date of the new account The date on which the user account will be disabled. The date is specified in the format YYYY-MM-DD. If not specified, useradd will use the default expiry date specified by the EXPIRE variable in /etc/default/useradd, or an empty string (no expiry) by default. -f, --inactive INACTIVE password inactivity period of the new account The number of days after a password expires until the account is permanently disabled. A value of 0 disables the account as soon as the password has expired, and a value of -1 disables the feature. If not specified, useradd will use the default inactivity period specified by the INACTIVE variable in /etc/default/useradd, or -1 by default. -g, --gid GROUP name or ID of the primary group of the new account -G, --groups GROUPS list of supplementary groups of the new account -h, --help display this help message and exit -k, --skel SKEL_DIR use this alternative skeleton directory -K, --key KEY=VALUE override /etc/login.defs defaults -l, --no-log-init do not add the user to the lastlog and faillog databases -m, --create-home create the user&apos;s home directory 強制！要建立使用者家目錄！(一般帳號預設值) -M, --no-create-home do not create the user&apos;s home directory 強制！不要建立使用者家目錄！(系統帳號預設值) -N, --no-user-group do not create a group with the same name as the user -o, --non-unique allow to create users with duplicate (non-unique) UID -p, --password PASSWORD encrypted password of the new account -r, --system create a system account -s, --shell SHELL login shell of the new account -u, --uid UID user ID of the new account -U, --user-group create a group with the same name as the user -Z, --selinux-user SEUSER use a specific SEUSER for the SELinux user mapping userdel –helpUsage: userdel [options] LOGINOptions:-f, --force force removal of files, This option forces the removal of the user account, even if the user is still logged in. It also forces userdel to remove the user´s home directory and mail spool, even if another user uses the same home directory or if the mail spool is not owned by the specified user. If USERGROUPS_ENAB is defined to yes in /etc/login.defs and if a group exists with the same name as the deleted user, then this group will be removed, even if it is still the primary group of another user. Note: This option is dangerous and may leave your system in an inconsistent state. even if not owned by user -h, --help display this help message and exit -r, --remove remove home directory and mail spool -Z, --selinux-user remove SELinux user from SELinux user mapping chage –helpUsage: chage [options] [LOGIN]Options:-d, --lastday LAST_DAY set date of last password change to LAST_DAY Set the number of days since January 1st, 1970 when the password was last changed. The date may also be expressed in the format YYYY-MM-DD (or the format more commonly used in your area). -E, --expiredate EXPIRE_DATE set account expiration date to EXPIRE_DATE -h, --help display this help message and exit -I, --inactive INACTIVE set password inactive after expiration to INACTIVE -l, --list show account aging information -m, --mindays MIN_DAYS set minimum number of days before password change to MIN_DAYS -M, --maxdays MAX_DAYS set maximim number of days before password change to MAX_DAYS -W, --warndays WARN_DAYS set expiration warning days to WARN_DAYS [1.153_old]$ sudo cat /etc/passwd |awk -F: ‘ $3 &gt; 500 ‘123456789101112131415nfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologinmysql:x:501:501::/home/mysql:/bin/bashsvn:x:502:502::/home/svn:/bin/bashxu:x:503:0::/home/james.xu:/bin/bashsun:x:504:0::/home/sam.sun:/bin/bashzhang:x:505:0::/home/daniel.zhang:/bin/bashzhang:x:506:0::/home/david.zhang:/bin/bashxie:x:509:0::/home/jiashui.xie:/bin/bashfu:x:512:0::/home/qiang.fu:/bin/bashyan:x:513:0::/home/elaine.yan:/bin/bashtcly:x:514:514::/home/u_tcly:/bin/bashluo:x:515:0::/home/hui.luo:/bin/bashhan:x:516:0::/home/tao.han:/bin/bashguo:x:517:0::/home/wade.guo:/bin/bashkebyn:x:518:0::/home/kebyn.yin:/bin/bash useradd.sh1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/bin/bashunset nameunset name_listunset igroupadd -g 501 mysqluseradd -u 501 -g 501 mysqlecho &apos;mysql&apos; | passwd --stdin mysql#chage -d 0 mysqlgroupadd -g 502 svnuseradd -u 502 -g 502 svnecho &apos;svn&apos; | passwd --stdin svn#chage -d 0 svngroupadd -g 503 james.xuuseradd -u 503 -g 0 james.xupasswd james.xuchage -d 0 james.xu#用户组从503开始i=503name_list=$(cat list.txt | awk -F: &apos; $3&gt;503 &#123;print $1&#125;&apos;)for name in $name_list;do if [ &quot;$name&quot; = &quot;nfsnobody&quot; ];then continue fi #groupadd -g $i $name #useradd -u $i -g $i $name useradd -u $i -g 0 $name echo &quot;$name&quot; | passwd --stdin $name chage -d 0 $name i=$[ i + 1 ]doneunset $nameunset $name_idread -&quot;请输入取消root组的用户名&quot; $namename_id=$(id -u $name)groupadd -g $name_id $nameusermod -g $name_id $namecat /etc/passwd |awk -F: &apos; $3 &gt; 500 &apos;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[swap设置]]></title>
      <url>%2F2015%2F03%2F16%2Fswap%2F</url>
      <content type="text"><![CDATA[Swap 设置 检查 Swap 空间在设置 Swap 文件之前，有必要先检查一下系统里有没有既存的 Swap 文件。运行以下命令：1swapon -s 如果返回的信息概要是空的，则表示 Swap 文件不存在。 2.检查文件系统在设置 Swap 文件之前，同样有必要检查一下文件系统，看看是否有足够的硬盘空间来设置 Swap 。运行以下命令：1df -hal 检查返回的信息，还剩余足够的硬盘空间即可。 创建并允许 Swap 文件下面使用 dd 命令来创建 Swap 文件。1dd if=/dev/zero of=/tmp/swapfile bs=1024 count=1024k 参数解读： if=文件名：输入文件名，缺省为标准输入。即指定源文件。&lt; if=input file &gt; of=文件名：输出文件名，缺省为标准输出。即指定目的文件。&lt; of=output file &gt; bs=bytes：同时设置读入/输出的块大小为bytes个字节 count=blocks：仅拷贝blocks个块，块大小等于bs指定的字节数。 最后，赋予 Swap 文件适当的权限：12chown root:root /tmp/swapfile chmod 600 /tmp/swapfile 格式化并激活 Swap 文件 上面已经创建好 Swap 文件，还需要格式化后才能使用。12mkswap /tmp/swapfileswapon /tmp/swapfile 以上步骤做完，再次运行命令：12345swapon -sFilename Type Size Used Priority/tmp/swapfile file 524284 0 -1 如果要机器重启的时候自动挂载 Swap ，那么还需要修改 fstab 配置。 1/tmp/swapfile swap swap defaults 0 0 同时，我们还可以修改 Linux Swap 空间的 swappiness ，降低对硬盘的缓存。 Linux 会使用硬盘的一部分做为 Swap 分区，用来进行进程调度–进程是正在运行的程序–把当前不用的进程调成‘等待（standby）’，甚至‘睡眠（sleep）’，一旦要用，再调成‘活动（active）’，睡眠的进程就会在 Swap 分区，把内存空出来让给‘活动’的进程。 如果内存够大，应当告诉 Linux 不必太多的使用 Swap 分区，可以通过修改 swappiness 的参数来设置。swappiness=0 的时候表示最大限度使用物理内存，然后才是 Swap 空间，swappiness＝100 的时候表示积极的使用 Swap 分区，并且把内存上的数据及时的搬运到 Swap 空间里面。 在 CentOS 中，swappiness 的默认值是60。通过以下命令可以看到： 1cat /proc/sys/vm/swappiness 返回值60 我们可以调整 swappiness 的值到一个合适的参数，从而达到最优化使用 Swap 的目的。这里我们将其设为10。使用 sysctl 命令： 1sysctl vm.swappiness=10 但是这只是临时性的修改，在你重启系统后会恢复默认的60，要永久设置，还需要在 vim 中修改sysctl.conf：1234vi /etc/sysctl.conf# Search for the vm.swappiness setting. Uncomment and change it as necessary.vm.swappiness=10 这样一来，Swap 分区重启后都会生效了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[apache_conf]]></title>
      <url>%2F2014%2F04%2F06%2Fapache_conf%2F</url>
      <content type="text"><![CDATA[尽量安装新版本的Apache 禁用不需要的模块，找到httpd.conf的loadModule行，对于不需要的用#注释掉 设置Apache的bin、conf、logs目录属主为root，权限为755 将Apache以专用的用户身份运行，配置httpd.conf 12User www-dataGroup www-data 禁止目录索引，关闭服务端SSI包含 123&lt;Directory/var/www/html&gt; Options -Indexes -Includes&lt;/Directory&gt; 禁止对目录配置文件进行重载 123&lt;Directory/&gt; AllowOverride None&lt;/Directory&gt; 仅允许访问指定目录。对根目录设置禁止访问，然后对需要让用户访问的目录开放访问权限 12345678&lt;Directory/&gt; Order deny,allow Deny from all&lt;/Directory&gt;&lt;Directory&quot;/var/www/www.example.com&quot;&gt; Order allow,deny Allow from all&lt;/Directory&gt; 隐藏特征，不展示Web服务器类型和版本 12ServerSignatureOffServerTokensProd 目录访问限制，可以设置重要目录只允许特定的IP访问 12345&lt;Directory&quot;/var/www/www.example.com/admin&quot;&gt; order deny,allow denyfrom all allowfrom 10.1.0.0/16&lt;/Directory&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[c语言写入文件简易应用]]></title>
      <url>%2F2014%2F03%2F25%2Fc_1%2F</url>
      <content type="text"><![CDATA[功能输入文件名后创建c文件，并用vc6打开c文件 1234567891011121314151617181920212223242526272829303132333435#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;windows.h&gt;int main ()&#123; FILE*fp; char ch ,filename[256]; printf(&quot;filename:&quot;); scanf(&quot;%s&quot;,filename); strcat(filename,&quot;.c&quot;); if ((fp=fopen(filename,&quot;w&quot;)) == NULL) &#123; printf (&quot;erro\n&quot;); return 0; exit (0); &#125; ch=getchar(); printf(&quot;EOF for #\n&quot;); ch=getchar(); if(ch != &apos;\n&apos;) &#123; while(ch != &apos;#&apos;) &#123; fputc(ch,fp);// putchar(ch); ch=getchar(); &#125; &#125; fclose(fp); putchar(256); ShellExecute(NULL,&quot;open&quot;,filename,&quot;D:/VC98/Bin/MSDEV.EXE&quot;,NULL,SW_SHOWNORMAL); return 0; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[grep]]></title>
      <url>%2F2014%2F03%2F20%2Fgrep%2F</url>
      <content type="text"><![CDATA[grep（global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。选项12345678910111213141516171819202122232425-a 不要忽略二进制数据。 -A&lt;显示列数&gt; 除了显示符合范本样式的那一行之外，并显示该行之后的内容。 -b 在显示符合范本样式的那一行之外，并显示该行之前的内容。 -c 计算符合范本样式的列数。 -C&lt;显示列数&gt;或-&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之前后的内容。 -d&lt;进行动作&gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep命令将回报信息并停止动作。 -e&lt;范本样式&gt; 指定字符串作为查找文件内容的范本样式。 -E 将范本样式为延伸的普通表示法来使用，意味着使用能使用扩展正则表达式。 -f&lt;范本文件&gt; 指定范本文件，其内容有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每一列的范本样式。 -F 将范本样式视为固定字符串的列表。 -G 将范本样式视为普通的表示法来使用。 -h 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。 -H 在显示符合范本样式的那一列之前，标示该列的文件名称。 -i 胡列字符大小写的差别。 -l 列出文件内容符合指定的范本样式的文件名称。 -L 列出文件内容不符合指定的范本样式的文件名称。 -n 在显示符合范本样式的那一列之前，标示出该列的编号。 -q 不显示任何信息。 -R/-r 此参数的效果和指定“-d recurse”参数相同。 -s 不显示错误信息。 -v 反转查找。 -w 只显示全字符合的列。 -x 只显示全列符合的列。 -y 此参数效果跟“-i”相同。 -o 只输出文件中匹配到的部分。 grep命令常见用法在文件中搜索一个单词，命令会返回一个包含“match_pattern”的文本行：grep match_pattern file_name grep &quot;match_pattern&quot; file_name 在多个文件中查找：grep &quot;match_pattern&quot; file_1 file_2 file_3 ... 输出除之外的所有行 -v 选项：grep -v &quot;match_pattern&quot; file_name 标记匹配颜色 –color=auto 选项：grep &quot;match_pattern&quot; file_name --color=auto 使用正则表达式 -E 选项：grep -E &quot;[1-9]+&quot; 或 egrep &quot;[1-9]+&quot; 只输出文件中匹配到的部分 -o 选项：echo this is a test line. | grep -o -E &quot;[a-z]+\.&quot; line. echo this is a test line. | egrep -o &quot;[a-z]+\.&quot; line. 统计文件或者文本中包含匹配字符串的行数 -c 选项：grep -c &quot;text&quot; file_name 输出包含匹配字符串的行数 -n 选项：grep &quot;text&quot; -n file_name 或 cat file_name | grep &quot;text&quot; -n 多个文件grep &quot;text&quot; -n file_1 file_2 打印样式匹配所位于的字符或字节偏移：echo gun is not unix | grep -b -o &quot;not&quot; 7:not 一行中字符串的字符便宜是从该行的第一个字符开始计算，起始值为0。选项 -b -o 一般总是配合使用。搜索多个文件并查找匹配文本在哪些文件中：grep -l &quot;text&quot; file1 file2 file3... grep递归搜索文件在多级目录中对文本进行递归搜索：grep &quot;text&quot; . -r -n .表示当前目录。忽略匹配样式中的字符大小写：echo &quot;hello world&quot; | grep -i &quot;HELLO&quot; hello 选项 -e 制动多个匹配样式：echo this is a text line | grep -e &quot;is&quot; -e &quot;line&quot; -o is line 也可以使用-f选项来匹配多个样式，在样式文件中逐行写出需要匹配的字符。cat patfile aaa bbb echo aaa bbb ccc ddd eee | grep -f patfile -o 在grep搜索结果中包括或者排除指定文件：只在目录中所有的.php和.html文件中递归搜索字符”main()”grep &quot;main()&quot; . -r --include *.{php,html} 在搜索结果中排除所有README文件grep &quot;main()&quot; . -r --exclude &quot;README&quot; 在搜索结果中排除filelist文件列表里的文件grep &quot;main()&quot; . -r --exclude-from filelist 使用0值字节后缀的grep与xargs：测试文件：echo &quot;aaa&quot; &gt; file1 echo &quot;bbb&quot; &gt; file2 echo &quot;aaa&quot; &gt; file3 grep &quot;aaa&quot; file* -lZ | xargs -0 rm 执行后会删除file1和file3，grep输出用-Z选项来指定以0值字节作为终结符文件名（\0），xargs -0 读取输入并用0值字节终结符分隔文件名，然后删除匹配文件，-Z通常和-l结合使用。grep静默输出：grep -q &quot;test&quot; filename 不会输出任何信息，如果命令运行成功返回0，失败则返回非0值。一般用于条件测试。打印出匹配文本之前或者之后的行：显示匹配某个结果之后的3行，使用 -A 选项：seq 10 | grep &quot;5&quot; -A 3 5 6 7 8 显示匹配某个结果之前的3行，使用 -B 选项：seq 10 | grep &quot;5&quot; -B 3 2 3 4 5 显示匹配某个结果的前三行和后三行，使用 -C 选项：seq 10 | grep &quot;5&quot; -C 3 2 3 4 5 6 7 8 如果匹配结果有多个，会用“–”作为各匹配结果之间的分隔符：echo -e &quot;a\nb\nc\na\nb\nc&quot; | grep a -A 1 a b -- a b]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[awk]]></title>
      <url>%2F2014%2F03%2F20%2Fawk%2F</url>
      <content type="text"><![CDATA[awk是一种编程语言，用于在linux/unix下对文本和数据进行处理。#####数据可以来自标准输入(stdin)、一个或多个文件，或其它命令的输出。它支持用户自定义函数和动态正则表达式等先进功能，是linux/unix下的一个强大编程工具。它在命令行中使用，但更多是作为脚本来使用。awk有很多内建的功能，比如数组、函数等，这是它和C语言的相同之处，灵活性是awk最大的优势。 awk命令格式和选项语法形式awk [options] &apos;script&apos; var=value file(s) awk [options] -f scriptfile var=value file(s) 常用命令选项-F fs fs指定输入分隔符，fs可以是字符串或正则表达式，如-F: -v var=value 赋值一个用户定义变量，将外部变量传递给awk -f scripfile 从脚本文件中读取awk命令 -m[fr] val 对val值设置内在限制，-mf选项限制分配给val的最大块数目； -mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。 awk模式和操作#####awk脚本是由模式和操作组成的。 模式 模式可以是以下任意一个： /正则表达式/：使用通配符的扩展集。 关系表达式：使用运算符进行操作，可以是字符串或数字的比较测试。 模式匹配表达式：用运算符~（匹配）和~!（不匹配）。 BEGIN语句块、pattern语句块、END语句块：参见awk的工作原理 操作 操作由一个或多个命令、函数、表达式组成，之间由换行符或分号隔开，并位于大括号内，主要部分是： 变量或数组赋值 输出命令 内置函数 控制流语句 awk脚本基本结构awk &apos;BEGIN{ print &quot;start&quot; } pattern{ commands } END{ print &quot;end&quot; }&apos; file 一个awk脚本通常由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块3部分组成，这三个部分是可选的。任意一个部分都可以不出现在脚本中，脚本通常是被单引号或双引号中，例如：awk &apos;BEGIN{ i=0 } { i++ } END{ print i }&apos; filename awk &quot;BEGIN{ i=0 } { i++ } END{ print i }&quot; filename awk的工作原理awk &apos;BEGIN{ commands } pattern{ commands } END{ commands }&apos; 执行BEGIN{ commands }语句块中的语句； 从文件或标准输入(stdin)读取一行，然后执行pattern{ commands }语句块，它逐行扫描文件，从第一行到最后一行重复这个过程，直到文件全部被读取完毕。 当读至输入流末尾时，执行END{ commands }语句块。 BEGIN语句块在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等语句通常可以写在BEGIN语句块中。 END语句块在awk从输入流中读取完所有的行之后即被执行，比如打印所有行的分析结果这类信息汇总都是在END语句块中完成，它也是一个可选语句块。 pattern语句块中的通用命令是最重要的部分，它也是可选的。如果没有提供pattern语句块，则默认执行{ print }，即打印每一个读取到的行，awk读取的每一行都会执行该语句块。 示例echo -e &quot;A line 1nA line 2&quot; | awk &apos;BEGIN{ print &quot;Start&quot; } { print } END{ print &quot;End&quot; }&apos; Start A line 1 A line 2 End 当使用不带参数的print时，它就打印当前行，当print的参数是以逗号进行分隔时，打印时则以空格作为定界符。在awk的print语句块中双引号是被当作拼接符使用，例如：echo | awk &apos;{ var1=&quot;v1&quot;; var2=&quot;v2&quot;; var3=&quot;v3&quot;; print var1,var2,var3; }&apos; v1 v2 v3 双引号拼接使用：echo | awk &apos;{ var1=&quot;v1&quot;; var2=&quot;v2&quot;; var3=&quot;v3&quot;; print var1&quot;=&quot;var2&quot;=&quot;var3; }&apos; v1=v2=v3 { }类似一个循环体，会对文件中的每一行进行迭代，通常变量初始化语句（如：i=0）以及打印文件头部的语句放入BEGIN语句块中，将打印的结果等语句放在END语句块中。 awk内置变量（预定义变量） 说明：[A][N][P][G]表示第一个支持变量的工具，[A]=awk、[N]=nawk、[P]=POSIXawk、[G]=gawk $n 当前记录的第n个字段，比如n为1表示第一个字段，n为2表示第二个字段。$0 这个变量包含执行过程中当前行的文本内容。12345678910111213141516171819| [N] | ARGC | 命令行参数的数目。 | | || [G] | ARGIND | 命令行中当前文件的位置（从0开始算）。 | | || [N] | ARGV | 包含命令行参数的数组。 [G] CONVFMT 数字转换格式（默认值为%.6g）。 | | || [P] | ENVIRON | 环境变量关联数组。 | | || [N] | ERRNO | 最后一个系统错误的描述。 | | || [G] | FIELDWIDTHS | 字段宽度列表（用空格键分隔）。 | | || [A] | FILENAME | 当前输入文件的名。 | | || [P] | FNR | 同NR，但相对于当前文件。 | | || [A] | FS | 字段分隔符（默认是任何空格）。 | | || [G] | IGNORECASE | 如果为真，则进行忽略大小写的匹配。 | | || [A] | NF | 表示字段数，在执行过程中对应于当前的字段数。 | | || [A] | NR | 表示记录数，在执行过程中对应于当前的行号。 | | || [A] | OFMT | 数字的输出格式（默认值是%.6g）。 | | || [A] | OFS | 输出字段分隔符（默认值是一个空格）。 | | || [A] | ORS | 输出记录分隔符（默认值是一个换行符）。 | | || [A] | RS | 记录分隔符（默认是一个换行符）。 | | || [N] | RSTART | 由match函数所匹配的字符串的第一个位置。 | | || [N] | RLENGTH | 由match函数所匹配的字符串的长度。 | | || [N] | SUBSEP | 数组下标分隔符（默认值是34）。 | | | 示例echo -e &quot;line1 f2 f3nline2 f4 f5nline3 f6 f7&quot; | awk &apos;{print &quot;Line No:&quot;NR&quot;, No of fields:&quot;NF, &quot;$0=&quot;$0, &quot;$1=&quot;$1, &quot;$2=&quot;$2, &quot;$3=&quot;$3}&apos; Line No:1, No of fields:3 $0=line1 f2 f3 $1=line1 $2=f2 $3=f3 Line No:2, No of fields:3 $0=line2 f4 f5 $1=line2 $2=f4 $3=f5 Line No:3, No of fields:3 $0=line3 f6 f7 $1=line3 $2=f6 $3=f7 使用print $NF可以打印出一行中的最后一个字段，使用$(NF-1)则是打印倒数第二个字段，其他以此类推：echo -e &quot;line1 f2 f3n line2 f4 f5&quot; | awk &apos;{print $NF}&apos; f3 f5 echo -e &quot;line1 f2 f3n line2 f4 f5&quot; | awk &apos;{print $(NF-1)}&apos; f2 f4 打印每一行的第二和第三个字段：awk &apos;{ print $2,$3 }&apos; filename 统计文件中的行数：awk &apos;END{ print NR }&apos; filename 以上命令只使用了END语句块，在读入每一行的时，awk会将NR更新为对应的行号，当到达最后一行NR的值就是最后一行的行号，所以END语句块中的NR就是文件的行数。 一个每一行中第一个字段值累加的例子：seq 5 | awk &apos;BEGIN{ sum=0; print &quot;总和：&quot; } { print $1&quot;+&quot;; sum+=$1 } END{ print &quot;等于&quot;; print sum }&apos; 总和： 1+ 2+ 3+ 4+ 5+ 等于 15 将外部变量值传递给awk借助-v选项，可以将外部值（并非来自stdin）传递给awk：VAR=10000 echo | awk -v VARIABLE=$VAR &apos;{ print VARIABLE }&apos; 另一种传递外部变量方法：var1=&quot;aaa&quot; var2=&quot;bbb&quot; echo | awk &apos;{ print v1,v2 }&apos; v1=$var1 v2=$var2 当输入来自于文件时使用：awk &apos;{ print v1,v2 }&apos; v1=$var1 v2=$var2 filename 以上方法中，变量之间用空格分隔作为awk的命令行参数跟随在BEGIN、{}和END语句块之后。 awk运算与判断作为一种程序设计语言所应具有的特点之一，awk支持多种运算，这些运算与C语言提供的基本相同。awk还提供了一系列内置的运算函数（如log、sqr、cos、sin等）和一些用于对字符串进行操作（运算）的函数（如length、substr等等）。这些函数的引用大大的提高了awk的运算功能。作为对条件转移指令的一部分，关系判断是每种程序设计语言都具备的功能，awk也不例外，awk中允许进行多种测试，作为样式匹配，还提供了模式匹配表达式~（匹配）和~!（不匹配）。作为对测试的一种扩充，awk也支持用逻辑运算符。 算术运算符123456|运算符 | 描述 || + - | 加，减 || * / &amp; | 乘，除与求余 || + - ! | 一元加，减和逻辑非 || ^ *** | 求幂 || ++ -- | 增加或减少，作为前缀或后缀 | 例：awk &apos;BEGIN{a=&quot;b&quot;;print a++,++a;}&apos; 0 2 注意：所有用作算术运算符进行操作，操作数自动转为数值，所有非数值都变为0 赋值运算符12| 运算符 | 描述 || = += -= *= /= %= ^= **= | 赋值语句 | 例：a+=5; 等价于：a=a+5; 其它同类 逻辑运算符123| 运算符 | 描述 || || | 逻辑或 || &amp;&amp; | 逻辑与 | 例：awk &apos;BEGIN{a=1;b=2;print (a&gt;5 &amp;&amp; b&lt;=2),(a&gt;5 || b&lt;=2);}&apos; 0 1 正则运算符12|运算符 |描述| ~ ~! |匹配正则表达式和不匹配正则表达式 例：awk &apos;BEGIN{a=&quot;100testa&quot;;if(a ~ /^100*/){print &quot;ok&quot;;}}&apos; ok 关系运算符12| 运算符 | 描述 || &lt; &lt;= &gt; &gt;= != == | 关系运算符 | 例：awk &apos;BEGIN{a=11;if(a &gt;= 9){print &quot;ok&quot;;}}&apos; ok 注意：&gt; &lt; 可以作为字符串比较，也可以用作数值比较，关键看操作数如果是字符串就会转换为字符串比较。两个都为数字才转为数值比较。字符串比较：按照ASCII码顺序比较。 其它运算符12345| 描述 | 运算符 || $ | 字段引用 || 字符串连接符 | 空格 || C条件表达式 | ?: || 数组中是否存在某键值 | in | 例：awk &apos;BEGIN{a=&quot;b&quot;;print a==&quot;b&quot;?&quot;ok&quot;:&quot;err&quot;;}&apos; ok awk &apos;BEGIN{a=&quot;b&quot;;arr[0]=&quot;b&quot;;arr[1]=&quot;c&quot;;print (a in arr);}&apos; 0 awk &apos;BEGIN{a=&quot;b&quot;;arr[0]=&quot;b&quot;;arr[&quot;b&quot;]=&quot;c&quot;;print (a in arr);}&apos; 1 运算级优先级表1234567891011121314| 级别 | 运算符 | 说明 || 1 | =,+=,-=,*=,/=,%=,&amp;=,^=,|=,&lt;&lt;=,&gt;&gt;= | 赋值、运算、赋值 || 2 | || | 逻辑或 || 3 | &amp;&amp; | 逻辑或 || 4 | | | 按位或 || 5 | ^ | 按位异或 || 6 | &amp; | 按位与 || 7 | ==,!= | 等于、不等于 || 8 | &lt;=,&gt;=,&lt;,&gt; | 小于等于、大于等于、小于、大于 || 9 | &lt;&lt;,&gt;&gt; | 按位左移、按位右移 || 10 | +,- | 加、减 || 11 | *,/,% | 乘、除、取模 || 12 | !,~ | 逻辑非、按位取反或补码 || 13 | -,+ | 正反 | 级别越高越优先 级别越高越优先 awk高级输入输出读取下一条记录awk中next语句使用：在循环逐行匹配，如果遇到next，就会跳过当前行，直接忽略下面语句。而进行下一行匹配。net语句一般用于多行合并： cat text.txt a b c d e awk &apos;NR%2==1{next}{print NR,$0;}&apos; text.txt 2 b 4 d 当记录行号除以2余1，就跳过当前行。下面的print NR,$0也不会执行。下一行开始，程序有开始判断NR%2值。这个时候记录行号是：2 ，就会执行下面语句块：’print NR,$0’分析发现需要将包含有“web”行进行跳过，然后需要将内容与下面行合并为一行： cat text.txt web01[192.168.2.100] httpd ok tomcat ok sendmail ok web02[192.168.2.101] httpd ok postfix ok web03[192.168.2.102] mysqld ok httpd ok 0 awk &apos;/^web/{T=$0;next;}{print T&quot;:t&quot;$0;}&apos; test.txt web01[192.168.2.100]: httpd ok web01[192.168.2.100]: tomcat ok web01[192.168.2.100]: sendmail ok web02[192.168.2.101]: httpd ok web02[192.168.2.101]: postfix ok web03[192.168.2.102]: mysqld ok web03[192.168.2.102]: httpd ok 简单地读取一条记录 awk getline用法： 输出重定向需用到getline函数。getline从标准输入、管道或者当前正在处理的文件之外的其他输入文件获得输入。它负责从输入获得下一行的内容，并给NF,NR和FNR等内建变量赋值。如果得到一条记录，getline函数返回1，如果到达文件的末尾就返回0，如果出现错误，例如打开文件失败，就返回-1。 getline语法：getline var，变量var包含了特定行的内容。 awk getline从整体上来说，用法说明：当其左右无重定向符|或&lt;时：getline作用于当前文件，读入当前文件的第一行给其后跟的变量var或$0（无变量），应该注意到，由于awk在处理getline之前已经读入了一行，所以getline得到的返回结果是隔行的。 当其左右有重定向符|或&lt;时：getline则作用于定向输入文件，由于该文件是刚打开，并没有被awk读入一行，只是getline读入，那么getline返回的是该文件的第一行，而不是隔行。 示例：执行linux的date命令，并通过管道输出给getline，然后再把输出赋值给自定义变量out，并打印它：awk &apos;BEGIN{ &quot;date&quot; | getline out; print out }&apos; test 执行shell的date命令，并通过管道输出给getline，然后getline从管道中读取并将输入赋值给out，split函数把变量out转化成数组mon，然后打印数组mon的第二个元素：awk &apos;BEGIN{ &quot;date&quot; | getline out; split(out,mon); print mon[2] }&apos; test 命令ls的输出传递给geline作为输入，循环使getline从ls的输出中读取一行，并把它打印到屏幕。这里没有输入文件，因为BEGIN块在打开输入文件前执行，所以可以忽略输入文件。awk &apos;BEGIN{ while( &quot;ls&quot; | getline) print }&apos; 关闭文件awk中允许在程序中关闭一个输入或输出文件，方法是使用awk的close语句。 close(&quot;filename&quot;) filename可以是getline打开的文件，也可以是stdin，包含文件名的变量或者getline使用的确切命令。或一个输出文件，可以是stdout，包含文件名的变量或使用管道的确切命令。 输出到一个文件awk中允许用如下方式将结果输出到一个文件： echo | awk &apos;{printf(&quot;hello word!n&quot;) &gt; &quot;datafile&quot;}&apos; 或 echo | awk &apos;{printf(&quot;hello word!n&quot;) &gt;&gt; &quot;datafile&quot;}&apos; 设置字段定界符默认的字段定界符是空格，可以使用-F “定界符” 明确指定一个定界符： awk -F: &apos;{ print $NF }&apos; /etc/passwd 或 awk &apos;BEGIN{ FS=&quot;:&quot; } { print $NF }&apos; /etc/passwd 在BEGIN语句块中则可以用OFS=“定界符”设置输出字段的定界符。 流程控制语句在linux awk的while、do-while和for语句中允许使用break,continue语句来控制流程走向，也允许使用exit这样的语句来退出。break中断当前正在执行的循环并跳到循环外执行下一条语句。if 是流程选择用法。awk中，流程控制语句，语法结构，与c语言类型。有了这些语句，其实很多shell程序都可以交给awk，而且性能是非常快的。下面是各个语句用法。 条件判断语句1234if(表达式) 语句1 else 语句2 格式中语句1可以是多个语句，为了方便判断和阅读，最好将多个语句用{}括起来。awk分枝结构允许嵌套，其格式为：123456if(表达式) &#123;语句1&#125; else if(表达式) &#123;语句2&#125; else &#123;语句3&#125; 示例：12345678910111213awk &apos;BEGIN&#123; test=100; if(test&gt;90)&#123; print &quot;very good&quot;; &#125; else if(test&gt;60)&#123; print &quot;good&quot;; &#125; else&#123; print &quot;no pass&quot;; &#125; &#125;&apos; very good 每条命令语句后面可以用;分号结尾。 循环语句while语句12while(表达式) &#123;语句&#125; 示例：12345678910awk &apos;BEGIN&#123; test=100; total=0; while(i&lt;=test)&#123; total+=i; i++; &#125; print total; &#125;&apos; 5050 for循环#####for循环有两种格式： 格式1： 1234567891011121314151617for(变量 in 数组) &#123;语句&#125; 示例： awk &apos;BEGIN&#123; for(k in ENVIRON)&#123; print k&quot;=&quot;ENVIRON[k]; &#125; &#125;&apos; TERM=linux G_BROKEN_FILENAMES=1 SHLVL=1 pwd=/root/text ...logname=root HOME=/root SSH_CLIENT=192.168.1.21 53087 22 ENVIRON是awk常量，是子典型数组。 格式2： 1234567891011for(变量;条件;表达式) &#123;语句&#125; 示例： awk &apos;BEGIN&#123; total=0; for(i=0;i&lt;=100;i++)&#123; total+=i; &#125; print total; &#125;&apos; 5050 do循环 12345678910do &#123;语句&#125; while(条件) 例子： awk &apos;BEGIN&#123; total=0; i=0; do &#123;total+=i;i++;&#125; while(i&lt;=100) print total; &#125;&apos; 5050 其他语句 break 当 break 语句用于 while 或 for 语句时，导致退出程序循环。 continue 当 continue 语句用于 while 或 for 语句时，使程序循环移动到下一个迭代。 next 能能够导致读入下一个输入行，并返回到脚本的顶部。这可以避免对当前输入行执行其他的操作过程。 exit 语句使主输入循环退出并将控制转移到END,如果END存在的话。如果没有定义END规则，或在END中应用exit语句，则终止脚本的执行。 数组应用数组是awk的灵魂，处理文本中最不能少的就是它的数组处理。因为数组索引（下标）可以是数字和字符串在awk中数组叫做关联数组(associative arrays)。awk 中的数组不必提前声明，也不必声明大小。数组元素用0或空字符串来初始化，这根据上下文而定。 数组的定义数字做数组索引（下标）： Array[1]=&quot;sun&quot; Array[2]=&quot;kai&quot; 字符串做数组索引（下标）： Array[&quot;first&quot;]=&quot;www&quot; Array[&quot;last&quot;]=&quot;name&quot; Array[&quot;birth&quot;]=&quot;1987&quot; 使用中print Array[1]会打印出sun；使用print Array[2]会打印出kai；使用print[“birth”]会得到1987。 读取数组的值 12&#123; for(item in array) &#123;print array[item]&#125;; &#125; #输出的顺序是随机的 &#123; for(i=1;i&lt;=len;i++) &#123;print array[i]&#125;; &#125; #Len是数组的长度 数组相关函数 得到数组长度： 123456789101112131415161718awk &apos;BEGIN&#123;info=&quot;it is a test&quot;;lens=split(info,tA,&quot; &quot;);print length(tA),lens;&#125;&apos; 4 4 length返回字符串以及数组长度，split进行分割字符串为数组，也会返回分割得到数组长度。 awk &apos;BEGIN&#123;info=&quot;it is a test&quot;;split(info,tA,&quot; &quot;);print asort(tA);&#125;&apos; 4 asort对数组进行排序，返回数组长度。 *** 输出数组内容（无序，有序输出）： awk &apos;BEGIN&#123;info=&quot;it is a test&quot;;split(info,tA,&quot; &quot;);for(k in tA)&#123;print k,tA[k];&#125;&#125;&apos; 4 test 1 it 2 is 3 a for…in输出，因为数组是关联数组，默认是无序的。所以通过for…in得到是无序的数组。如果需要得到有序数组，需要通过下标获得。 awk &apos;BEGIN&#123;info=&quot;it is a test&quot;;tlen=split(info,tA,&quot; &quot;);for(k=1;k&lt;=tlen;k++)&#123;print k,tA[k];&#125;&#125;&apos; 1 it 2 is 3 a 4 test 注意：数组下标是从1开始，与C数组不一样。 判断键值存在以及删除键值：错误的判断方法： 12345awk &apos;BEGIN&#123;tB[&quot;a&quot;]=&quot;a1&quot;;tB[&quot;b&quot;]=&quot;b1&quot;;if(tB[&quot;c&quot;]!=&quot;1&quot;)&#123;print &quot;no found&quot;;&#125;;for(k in tB)&#123;print k,tB[k];&#125;&#125;&apos; no found a a1 b b1 c 以上出现奇怪问题，tB[“c”]没有定义，但是循环时候，发现已经存在该键值，它的值为空，这里需要注意，awk数组是关联数组，只要通过数组引用它的key，就会自动创建改序列。 正确判断方法： 1234awk &apos;BEGIN&#123;tB[&quot;a&quot;]=&quot;a1&quot;;tB[&quot;b&quot;]=&quot;b1&quot;;if( &quot;c&quot; in tB)&#123;print &quot;ok&quot;;&#125;;for(k in tB)&#123;print k,tB[k];&#125;&#125;&apos; a a1 b b1 if(key in array)通过这种方法判断数组中是否包含key键值。 删除键值： 123[chengmo@localhost ~]$ awk &apos;BEGIN&#123;tB[&quot;a&quot;]=&quot;a1&quot;;tB[&quot;b&quot;]=&quot;b1&quot;;delete tB[&quot;a&quot;];for(k in tB)&#123;print k,tB[k];&#125;&#125;&apos; b b1 delete array[key]可以删除，对应数组key的，序列值。 二维、多维数组使用 123456789101112131415161718192021222324252627282930awk &apos;BEGIN&#123; for(i=1;i&lt;=9;i++)&#123; for(j=1;j&lt;=9;j++)&#123; tarr[i,j]=i*j; print i,&quot;*&quot;,j,&quot;=&quot;,tarr[i,j]; &#125; &#125; &#125;&apos; 1 * 1 = 1 1 * 2 = 2 1 * 3 = 3 1 * 4 = 4 1 * 5 = 5 1 * 6 = 6 ... 9 * 6 = 54 9 * 7 = 63 9 * 8 = 72 9 * 9 = 81 可以通过array[k,k2]引用获得数组内容。 另一种方法： awk &apos;BEGIN&#123; for(i=1;i&lt;=9;i++)&#123; for(j=1;j&lt;=9;j++)&#123; tarr[i,j]=i*j; &#125; &#125; for(m in tarr)&#123; split(m,tarr2,SUBSEP); print tarr2[1],&quot;*&quot;,tarr2[2],&quot;=&quot;,tarr[m]; &#125; &#125;&apos; 内置函数awk内置函数，主要分以下3种类似：算数函数、字符串函数、其它一般函数、时间函数。 算术函数12345678910|格式| 描述| |atan2( y, x )| 返回 y/x 的反正切。| |cos( x )| 返回 x 的余弦；x 是弧度。| |sin( x )| 返回 x 的正弦；x 是弧度。 ||exp( x )| 返回 x 幂函数。 ||log( x )| 返回 x 的自然对数。| |sqrt( x )| 返回 x 平方根。 ||int( x )| 返回 x 的截断至整数的值。 ||rand( )| 返回任意数字 n，其中 0 &lt;= n &lt; 1。| |srand( [expr] )| 将 rand 函数的种子值设置为 Expr 参数的值，或如果省略 Expr 参数则使用某天的时间。返回先前的种子值。 | 字符串函数123456789101112|格式| 描述| |gsub( Ere, Repl, [ In ] ) |除了正则表达式所有具体值被替代这点，它和 sub 函数完全一样地执行。 ||sub( Ere, Repl, [ In ] ) |用 Repl 参数指定的字符串替换 In 参数指定的字符串中的由 Ere 参数指定的扩展正则表达式的第一个具体值。sub 函数返回替换的数量。出现在 Repl 参数指定的字符串中的 &amp;（和符号）由 In 参数指定的与 Ere 参数的指定的扩展正则表达式匹配的字符串替换。如果未指定 In 参数，缺省值是整个记录（$0 记录变量）。 ||index( String1, String2 ) |在由 String1 参数指定的字符串（其中有出现 String2 指定的参数）中，返回位置，从 1 开始编号。如果 String2 参数不在 String1 参数中出现，则返回 0（零）。 ||length [(String)] |返回 String 参数指定的字符串的长度（字符形式）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。 ||blength [(String)] |返回 String 参数指定的字符串的长度（以字节为单位）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。 ||substr( String, M, [ N ] ) |返回具有 N 参数指定的字符数量子串。子串从 String 参数指定的字符串取得，其字符以 M 参数指定的位置开始。M 参数指定为将 String 参数中的第一个字符作为编号 1。如果未指定 N 参数，则子串的长度将是 M 参数指定的位置到 String 参数的末尾 的长度。| |match( String, Ere ) |在 String 参数指定的字符串（Ere 参数指定的扩展正则表达式出现在其中）中返回位置（字符形式），从 1 开始编号，或如果 Ere 参数不出现，则返回 0（零）。RSTART 特殊变量设置为返回值。RLENGTH 特殊变量设置为匹配的字符串的长度，或如果未找到任何匹配，则设置为 -1（负一）。 ||split( String, A, [Ere] ) |将 String 参数指定的参数分割为数组元素 A[1], A[2], . . ., A[n]，并返回 n 变量的值。此分隔可以通过 Ere 参数指定的扩展正则表达式进行，或用当前字段分隔符（FS 特殊变量）来进行（如果没有给出 Ere 参数）。除非上下文指明特定的元素还应具有一个数字值，否则 A 数组中的元素用字符串值来创建。| |tolower( String ) |返回 String 参数指定的字符串，字符串中每个大写字符将更改为小写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。 ||toupper( String ) |返回 String 参数指定的字符串，字符串中每个小写字符将更改为大写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。 ||sprintf(Format, Expr, Expr, . . . ) |根据 Format 参数指定的 printf 子例程格式字符串来格式化 Expr 参数指定的表达式并返回最后生成的字符串。| 注：Ere都可以是正则表达式。 格式化字符串输出（sprintf使用）格式化字符串格式：其中格式化字符串包括两部分内容：一部分是正常字符，这些字符将按原样输出; 另一部分是格式化规定字符，以”%”开始，后跟一个或几个规定字符,用来确定输出内容格式。1234567891011| 格式 | 描述 || %d | 十进制有符号整数 || %u | 十进制无符号整数 || %f | 浮点数 || %s | 字符串 || %c | 单个字符 || %p | 指针的值 || %e | 指数形式的浮点数 || %x | %X 无符号以十六进制表示的整数 || %o | 无符号以八进制表示的整数 || %g | 自动选择合适的表示法 | strftime日期和时间格式说明符12345678910111213141516171819202122232425| 格式 | 描述 || %a | 星期几的缩写(Sun) || %A | 星期几的完整写法(Sunday) || %b | 月名的缩写(Oct) || %B | 月名的完整写法(October) || %c | 本地日期和时间 || %d | 十进制日期 || %D | 日期 08/20/99 || %e | 日期，如果只有一位会补上一个空格 || %H | 用十进制表示24小时格式的小时 || %I | 用十进制表示12小时格式的小时 || %j | 从1月1日起一年中的第几天 || %m | 十进制表示的月份 || %M | 十进制表示的分钟 || %p | 12小时表示法(AM/PM) || %S | 十进制表示的秒 || %U | 十进制表示的一年中的第几个星期(星期天作为一个星期的开始) || %w | 十进制表示的星期几(星期天是0) || %W | 十进制表示的一年中的第几个星期(星期一作为一个星期的开始) || %x | 重新设置本地日期(08/20/99) || %X | 重新设置本地时间(12：00：00) || %y | 两位数字表示的年(99) || %Y | 当前月份 || %Z | 时区(PDT) || %% | 百分号(%) |]]></content>
    </entry>

    
  
  
</search>
